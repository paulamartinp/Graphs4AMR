{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import sklearn\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix, f1_score\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "import random, os, json\n",
    "# Configurar variables de entorno\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"  # \"-1\" significa deshabilitar todas las GPUs\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Masking, GRU, Dropout, Dense\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "import multiprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FUNCTIONS OF THE MODEL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reset Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reset_keras(seed=42):\n",
    "    \"\"\"Function to ensure that results from Keras models\n",
    "    are consistent and reproducible across different runs\"\"\"\n",
    "    \n",
    "    K.clear_session()\n",
    "    # 1. Set `PYTHONHASHSEED` environment variable at a fixed value\n",
    "    os.environ['PYTHONHASHSEED']=str(seed)\n",
    "    # 2. Set `python` built-in pseudo-random generator at a fixed value\n",
    "    random.seed(seed)\n",
    "    # 3. Set `numpy` pseudo-random generator at a fixed value\n",
    "    np.random.seed(seed)\n",
    "    # 4. Set `tensorflow` pseudo-random generator at a fixed value\n",
    "    tf.random.set_seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Building GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(hyperparameters):\n",
    "    \"\"\"\n",
    "    Builds a LSTM model based on several hyperparameters.\n",
    "\n",
    "    Args:\n",
    "        - hyperparameters: Dictionary containing the hyperparameters. \n",
    "    Returns:\n",
    "        - model: A tf.keras.Model with the compiled model.\n",
    "    \"\"\"\n",
    "    \n",
    "    dynamic_input = tf.keras.layers.Input(shape=(hyperparameters[\"n_time_steps\"], hyperparameters[\"layers\"][0]))\n",
    "    masked = tf.keras.layers.Masking(mask_value=hyperparameters['mask_value'])(dynamic_input)\n",
    "\n",
    "    gru = tf.keras.layers.GRU(\n",
    "        hyperparameters[\"layers\"][1],\n",
    "        dropout=hyperparameters['dropout'],\n",
    "        return_sequences=False,\n",
    "        activation=hyperparameters['activation'],\n",
    "        use_bias=True\n",
    "    )(masked)\n",
    "\n",
    "    output = tf.keras.layers.Dense(1, use_bias=True, activation=\"sigmoid\")(gru)\n",
    "\n",
    "    model = tf.keras.Model(dynamic_input, [output])\n",
    "    model.compile(\n",
    "        loss='binary_crossentropy',\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=hyperparameters[\"lr_scheduler\"]),\n",
    "        metrics=['accuracy', \"AUC\"]\n",
    "    )\n",
    "        \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Running the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_network(X_train, X_val, y_train, y_val, hyperparameters, seed):\n",
    "    \"\"\"\n",
    "    Trains and evaluates the built LSTM model based on the provided data and hyperparameters.\n",
    "\n",
    "    Args:\n",
    "        - X_train, X_val, y_train, y_val: numpy.ndarray. Training (T) and Validation (V) data labels.\n",
    "        - sample_weights_train, sample_weights_val: numpy.ndarray. Weights for the T and V data to handle class imbalance.\n",
    "        - hyperparameters: Dictionary containing the hyperparameters.\n",
    "        - seed: Integer seed for reproducibility.\n",
    "    Returns:\n",
    "        - model: A tf.keras.Model with the trained model.\n",
    "        - hist:  The training history.\n",
    "        - earlystopping: The early stopping callback.\n",
    "    \"\"\"\n",
    "    batch_size = hyperparameters['batch_size']\n",
    "    n_epochs_max = hyperparameters['n_epochs_max']    \n",
    "\n",
    "    model = None\n",
    "    model = build_model(hyperparameters)\n",
    "    earlystopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss',\n",
    "                                                  min_delta=hyperparameters[\"mindelta\"],\n",
    "                                                  patience=hyperparameters[\"patience\"],\n",
    "                                                  restore_best_weights=True,\n",
    "                                                  mode=\"min\")\n",
    "    hist = model.fit(X_train, y_train,\n",
    "                     validation_data=(X_val, y_val),\n",
    "                     callbacks=[earlystopping], batch_size=batch_size, epochs=n_epochs_max,\n",
    "                     verbose=hyperparameters['verbose'])\n",
    "    \n",
    "    return model, hist, earlystopping\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_combination(k, l, m, b, hyperparameters, dropout, layers, lr_scheduler, activation, seed, split, norm, n_time_steps):\n",
    "    hyperparameters_copy = hyperparameters.copy()\n",
    "    hyperparameters_copy['dropout'] = dropout[k]\n",
    "    hyperparameters_copy['layers'] = layers[l]\n",
    "    hyperparameters_copy['lr_scheduler'] = lr_scheduler[m]\n",
    "    hyperparameters_copy['activation'] = activation[b]\n",
    "    \n",
    "    v_val_loss = []\n",
    "    \n",
    "    X_train = np.load(\"../DATA/s\" + str(i) + \"/X_train_tensor_normPower2\" + \".npy\")\n",
    "    X_val = np.load(\"../DATA/s\" + str(i) + \"/X_val_tensor_normPower2\" + \".npy\")\n",
    "\n",
    "    y_train = pd.read_csv(\"../DATA/s\" + str(i) + \"/y_train_normPower2\" + \".csv\")\n",
    "    y_train = y_train[['individualMRGerm_stac']]\n",
    "    y_train = y_train.iloc[0:y_train.shape[0]:hyperparameters[\"n_time_steps\"]].reset_index(drop=True)\n",
    "\n",
    "    y_val = pd.read_csv(\"../DATA/s\" + str(i) + \"/y_val_normPower2\" + \".csv\")\n",
    "    y_val = y_val[['individualMRGerm_stac']]\n",
    "    y_val = y_val.iloc[0:y_val.shape[0]:hyperparameters[\"n_time_steps\"]].reset_index(drop=True)\n",
    "    \n",
    "    reset_keras()\n",
    "\n",
    "    model, hist, early = run_network(\n",
    "        X_train, X_val,\n",
    "        y_train,\n",
    "        y_val,\n",
    "        hyperparameters_copy,\n",
    "        seed\n",
    "    )\n",
    "\n",
    "    v_val_loss.append(np.min(hist.history[\"val_loss\"]))\n",
    "\n",
    "    metric_dev = np.mean(v_val_loss)\n",
    "    return (metric_dev, k, l, m, b, X_train, y_train, X_val, y_val)\n",
    "\n",
    "def myCVGridParallel(hyperparameters, dropout, lr_scheduler, layers, activation, seed, split, norm, n_time_steps=14):\n",
    "    \"\"\"Parallelized Grid Search. \n",
    "       Calculate metricDev based on the evaluation. Compares the metricDev with the current bestMetricDev. \n",
    "       If better, updates bestMetricDev and stores those hyperparameters in bestHyperparameters.\n",
    "       \n",
    "    Args:\n",
    "        - hyperparameters: Dictionary containing the hyperparameters.\n",
    "        - dropout: A list of dropout rates.\n",
    "        - lr_scheduler: A list of learning rates.\n",
    "        - layers: A list of layer configurations.\n",
    "        - seed : Seed value for reproducibility.\n",
    "        - split: String indicating the data split.\n",
    "        - norm: String with the type of normalization applied to the data.\n",
    "    Returns:\n",
    "        - bestHyperparameters: A dictionary with the best hyperparameters found and Train and Val data.\n",
    "    \"\"\"\n",
    "    bestHyperparameters = {}\n",
    "    bestMetricDev = np.inf\n",
    "\n",
    "    \n",
    "#     for k in range(len(dropout)):\n",
    "#         for l in range(len(layers)):\n",
    "#             for m in range(len(lr_scheduler)):\n",
    "#                 for b in range(len(activation)):\n",
    "#                     metric_dev, k, l, m, b, X_train, y_train, X_val, y_val = evaluate_combination(k, l, m, b, hyperparameters, dropout, layers, lr_scheduler, activation, seed, split, norm, n_time_steps)\n",
    "    \n",
    "    num_cores = multiprocessing.cpu_count()\n",
    "    results = Parallel(n_jobs=num_cores)(\n",
    "        delayed(evaluate_combination)(k, l, m, b, hyperparameters, dropout, layers, lr_scheduler, activation, seed, split, norm, n_time_steps)\n",
    "        for k in range(len(dropout))\n",
    "        for l in range(len(layers))\n",
    "        for m in range(len(lr_scheduler))\n",
    "        for b in range(len(activation))\n",
    "    )\n",
    "\n",
    "    for metric_dev, k, l, m, b, X_train, y_train, X_val, y_val in results:\n",
    "        if metric_dev < bestMetricDev:\n",
    "            print(\"\\t\\t\\tCambio the best\", bestMetricDev, \"por metric dev:\", metric_dev)\n",
    "            bestMetricDev = metric_dev\n",
    "            bestHyperparameters = {\n",
    "                'dropout': dropout[k],\n",
    "                'layers': layers[l],\n",
    "                'lr_scheduler': lr_scheduler[m],\n",
    "                'activation': activation[b],\n",
    "                'X_train': X_train,\n",
    "                'y_train': y_train,\n",
    "                'X_val': X_val,\n",
    "                'y_val': y_val\n",
    "            }\n",
    "\n",
    "    return bestHyperparameters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters\n",
    "In the dictionary, hyperparameters related to: data, training, evaluation, regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "seeds = [42, 76, 124, 163, 192, 205]\n",
    "\n",
    "input_shape = 80\n",
    "n_time_steps = 14\n",
    "batch_size = 32\n",
    "n_epochs_max = 1000\n",
    "\n",
    "layer_list = [\n",
    "    [input_shape, 20, 1],  [input_shape, 30, 1], [input_shape, 40, 1], \n",
    "    [input_shape, 50, 1], [input_shape, 60, 1]\n",
    "]\n",
    "\n",
    "dropout = [0.0, 0.15, 0.3]\n",
    "lr_scheduler = [1e-1, 1e-2, 1e-3, 1e-4]\n",
    "\n",
    "activation = ['tanh', 'LeakyReLU']\n",
    " \n",
    "norm = \"robustNorm\"\n",
    "\n",
    "hyperparameters = {\n",
    "    \"n_time_steps\": n_time_steps,\n",
    "    \"mask_value\": 666,\n",
    "    \"batch_size\": batch_size,\n",
    "    \"n_epochs_max\": n_epochs_max,\n",
    "    \"monitor\": \"val_loss\",\n",
    "    \"mindelta\": 0,\n",
    "    \"patience\": 25,\n",
    "    \"dropout\": 0.0,\n",
    "    \"verbose\": 0,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\t\tCambio the best inf por metric dev: 0.36251774430274963\n",
      "\t\t\tCambio the best 0.36251774430274963 por metric dev: 0.3127076327800751\n",
      "\t\t\tCambio the best 0.3127076327800751 por metric dev: 0.25204935669898987\n",
      "\t\t\tCambio the best inf por metric dev: 0.29703181982040405\n",
      "\t\t\tCambio the best 0.29703181982040405 por metric dev: 0.29395484924316406\n",
      "\t\t\tCambio the best 0.29395484924316406 por metric dev: 0.28914982080459595\n",
      "\t\t\tCambio the best 0.28914982080459595 por metric dev: 0.28896594047546387\n",
      "\t\t\tCambio the best 0.28896594047546387 por metric dev: 0.2775346636772156\n",
      "\t\t\tCambio the best inf por metric dev: 0.3293093144893646\n",
      "\t\t\tCambio the best 0.3293093144893646 por metric dev: 0.30943480134010315\n",
      "\t\t\tCambio the best 0.30943480134010315 por metric dev: 0.30369889736175537\n",
      "\t\t\tCambio the best 0.30369889736175537 por metric dev: 0.3033117353916168\n",
      "\t\t\tCambio the best 0.3033117353916168 por metric dev: 0.2621467709541321\n",
      "\t\t\tCambio the best inf por metric dev: 0.34157827496528625\n",
      "\t\t\tCambio the best 0.34157827496528625 por metric dev: 0.3404841423034668\n",
      "\t\t\tCambio the best 0.3404841423034668 por metric dev: 0.3399185538291931\n",
      "\t\t\tCambio the best 0.3399185538291931 por metric dev: 0.3165580630302429\n",
      "\t\t\tCambio the best 0.3165580630302429 por metric dev: 0.29932501912117004\n",
      "\t\t\tCambio the best 0.29932501912117004 por metric dev: 0.29731863737106323\n",
      "\t\t\tCambio the best 0.29731863737106323 por metric dev: 0.2908993065357208\n",
      "\t\t\tCambio the best 0.2908993065357208 por metric dev: 0.28952890634536743\n",
      "\t\t\tCambio the best inf por metric dev: 0.3404371738433838\n",
      "\t\t\tCambio the best 0.3404371738433838 por metric dev: 0.31342244148254395\n",
      "\t\t\tCambio the best 0.31342244148254395 por metric dev: 0.29577890038490295\n",
      "\t\t\tCambio the best 0.29577890038490295 por metric dev: 0.2930032014846802\n",
      "\t\t\tCambio the best 0.2930032014846802 por metric dev: 0.23207175731658936\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "run_model = True\n",
    "if run_model:\n",
    "    loss_train = []\n",
    "    loss_dev = []\n",
    "    v_models = []\n",
    "\n",
    "    bestHyperparameters_bySplit = {}\n",
    "    y_pred_by_split = {}\n",
    "\n",
    "    for i in [1,2,3,4,5]:\n",
    "        init = time.time()\n",
    "        # LOAD TEST AND PRE-TRAIN\n",
    "        X_test = np.load(\"../DATA/s\" + str(i) + \"/X_test_tensor_normPower2\" + \".npy\")\n",
    "\n",
    "        y_test = pd.read_csv(\"../DATA/s\" + str(i) + \"/y_test_normPower2\" + \".csv\")\n",
    "        y_test = y_test[['individualMRGerm_stac']]\n",
    "        y_test = y_test.iloc[0:y_test.shape[0]:hyperparameters[\"n_time_steps\"]].reset_index(drop=True)\n",
    "\n",
    "        # GridSearch of hyperparameters \n",
    "        bestHyperparameters = myCVGridParallel(hyperparameters,\n",
    "                                               dropout,\n",
    "                                               lr_scheduler,\n",
    "                                               layer_list,\n",
    "                                               activation,\n",
    "                                               seeds[i],\n",
    "                                               \"s\"+str(i),\n",
    "                                               norm)\n",
    "        fin = time.time()\n",
    "        X_train = bestHyperparameters[\"X_train\"]\n",
    "        y_train = bestHyperparameters[\"y_train\"]\n",
    "        X_val = bestHyperparameters[\"X_val\"]\n",
    "        y_val = bestHyperparameters[\"y_val\"]\n",
    "\n",
    "        bestHyperparameters_bySplit[str(i)] = bestHyperparameters\n",
    "\n",
    "        # Save best hyperparameters for current split\n",
    "        split_directory = './Results_GRU/split_' + str(i)\n",
    "        if not os.path.exists(split_directory):\n",
    "            os.makedirs(split_directory)\n",
    "\n",
    "        with open(os.path.join(split_directory, f\"bestHyperparameters_split_{i}.pkl\"), 'wb') as f:\n",
    "            pickle.dump(bestHyperparameters, f)\n",
    "\n",
    "        hyperparameters = {\n",
    "            'n_time_steps': hyperparameters[\"n_time_steps\"],\n",
    "            'mask_value': hyperparameters[\"mask_value\"],\n",
    "\n",
    "            'batch_size': hyperparameters[\"batch_size\"],\n",
    "            'n_epochs_max': hyperparameters[\"n_epochs_max\"],\n",
    "            'monitor':  hyperparameters[\"monitor\"],\n",
    "            \"mindelta\": hyperparameters[\"mindelta\"],\n",
    "            \"patience\": hyperparameters[\"patience\"],\n",
    "            \"dropout\": bestHyperparameters[\"dropout\"],\n",
    "            \"layers\": bestHyperparameters[\"layers\"],\n",
    "            \"lr_scheduler\": bestHyperparameters[\"lr_scheduler\"],\n",
    "            \"activation\": bestHyperparameters[\"activation\"],\n",
    "            'verbose': 0\n",
    "        }\n",
    "\n",
    "        # --- TRY ON TEST ----------------------------------------------------------------------\n",
    "        reset_keras()\n",
    "\n",
    "        model, hist, early = run_network(\n",
    "            X_train, X_val,\n",
    "            y_train,\n",
    "            y_val,\n",
    "            hyperparameters,\n",
    "            seeds[i-1]\n",
    "        )\n",
    "\n",
    "        v_models.append(model)\n",
    "        loss_train.append(hist.history['loss'])\n",
    "        loss_dev.append(hist.history['val_loss'])\n",
    "\n",
    "        y_pred = model.predict(x=X_test)\n",
    "        y_pred_by_split[str(i)] = y_pred\n",
    "\n",
    "        # Save y_pred for current split\n",
    "        with open(os.path.join(split_directory, f\"y_pred_split_{i}.pkl\"), 'wb') as f:\n",
    "            pickle.dump(y_pred, f)\n",
    "\n",
    "        # Save model for current split\n",
    "        model_filename = os.path.join(split_directory, f\"model_split_{i}.h5\")\n",
    "        model.save(model_filename)\n",
    "\n",
    "    # END EXECUTION - SAVE AGGREGATED RESULTS\n",
    "    directory = './Results_GRU'\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "\n",
    "    def save_to_pickle(data, filename):\n",
    "        with open(filename, 'wb') as f:\n",
    "            pickle.dump(data, f)\n",
    "\n",
    "    save_to_pickle(bestHyperparameters_bySplit, os.path.join(directory, \"bestHyperparameters_bySplit.pkl\"))\n",
    "    save_to_pickle(y_pred_by_split, os.path.join(directory, \"y_pred_by_split.pkl\"))\n",
    "    \n",
    "    for i, model in enumerate(v_models):\n",
    "        model_filename = os.path.join(directory, f\"model_{i}.h5\")\n",
    "        model.save(model_filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'1': {'dropout': 0.0,\n",
       "  'layers': [80, 30, 1],\n",
       "  'lr_scheduler': 0.1,\n",
       "  'activation': 'tanh',\n",
       "  'X_train': array([[[ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "           -1.72938632e-03, -3.98213791e-04,  9.31827501e-05],\n",
       "          [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "           -1.72938632e-03, -3.98213791e-04,  9.31827501e-05],\n",
       "          [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "           -1.72938632e-03, -3.98213791e-04,  9.31827501e-05],\n",
       "          ...,\n",
       "          [ 6.66000000e+02,  6.66000000e+02,  6.66000000e+02, ...,\n",
       "            6.66000000e+02,  6.66000000e+02,  6.66000000e+02],\n",
       "          [ 6.66000000e+02,  6.66000000e+02,  6.66000000e+02, ...,\n",
       "            6.66000000e+02,  6.66000000e+02,  6.66000000e+02],\n",
       "          [ 6.66000000e+02,  6.66000000e+02,  6.66000000e+02, ...,\n",
       "            6.66000000e+02,  6.66000000e+02,  6.66000000e+02]],\n",
       "  \n",
       "         [[ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "           -1.72938632e-03, -3.98213791e-04,  9.31827501e-05],\n",
       "          [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "           -1.72938632e-03, -3.98213791e-04,  9.31827501e-05],\n",
       "          [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "           -1.72938632e-03, -3.98213791e-04,  9.31827501e-05],\n",
       "          ...,\n",
       "          [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "           -1.72938632e-03, -3.98213791e-04,  9.31827501e-05],\n",
       "          [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "           -1.72938632e-03, -3.98213791e-04,  9.31827501e-05],\n",
       "          [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "           -1.72938632e-03, -3.98213791e-04,  9.31827501e-05]],\n",
       "  \n",
       "         [[ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "           -1.72938632e-03, -3.98213791e-04,  9.31827501e-05],\n",
       "          [ 6.66000000e+02,  6.66000000e+02,  6.66000000e+02, ...,\n",
       "            6.66000000e+02,  6.66000000e+02,  6.66000000e+02],\n",
       "          [ 6.66000000e+02,  6.66000000e+02,  6.66000000e+02, ...,\n",
       "            6.66000000e+02,  6.66000000e+02,  6.66000000e+02],\n",
       "          ...,\n",
       "          [ 6.66000000e+02,  6.66000000e+02,  6.66000000e+02, ...,\n",
       "            6.66000000e+02,  6.66000000e+02,  6.66000000e+02],\n",
       "          [ 6.66000000e+02,  6.66000000e+02,  6.66000000e+02, ...,\n",
       "            6.66000000e+02,  6.66000000e+02,  6.66000000e+02],\n",
       "          [ 6.66000000e+02,  6.66000000e+02,  6.66000000e+02, ...,\n",
       "            6.66000000e+02,  6.66000000e+02,  6.66000000e+02]],\n",
       "  \n",
       "         ...,\n",
       "  \n",
       "         [[ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "           -1.72938632e-03, -3.98213791e-04,  9.31827501e-05],\n",
       "          [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "           -1.72938632e-03, -3.98213791e-04, -6.28465881e-03],\n",
       "          [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "           -1.72938632e-03, -3.98213791e-04, -6.28465881e-03],\n",
       "          ...,\n",
       "          [ 6.66000000e+02,  6.66000000e+02,  6.66000000e+02, ...,\n",
       "            6.66000000e+02,  6.66000000e+02,  6.66000000e+02],\n",
       "          [ 6.66000000e+02,  6.66000000e+02,  6.66000000e+02, ...,\n",
       "            6.66000000e+02,  6.66000000e+02,  6.66000000e+02],\n",
       "          [ 6.66000000e+02,  6.66000000e+02,  6.66000000e+02, ...,\n",
       "            6.66000000e+02,  6.66000000e+02,  6.66000000e+02]],\n",
       "  \n",
       "         [[ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "           -1.72938632e-03, -3.98213791e-04,  9.31827501e-05],\n",
       "          [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "           -1.72938632e-03, -3.98213791e-04,  9.31827501e-05],\n",
       "          [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "           -1.72938632e-03, -3.98213791e-04,  6.47102431e-03],\n",
       "          ...,\n",
       "          [ 0.00000000e+00,  1.00000000e+00,  0.00000000e+00, ...,\n",
       "           -1.72938632e-03, -3.98213791e-04,  9.31827501e-05],\n",
       "          [ 0.00000000e+00,  1.00000000e+00,  0.00000000e+00, ...,\n",
       "           -1.72938632e-03, -3.98213791e-04,  9.31827501e-05],\n",
       "          [ 0.00000000e+00,  1.00000000e+00,  0.00000000e+00, ...,\n",
       "           -1.72938632e-03, -3.98213791e-04,  9.31827501e-05]],\n",
       "  \n",
       "         [[ 1.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "           -1.72938632e-03, -3.98213791e-04,  6.47102431e-03],\n",
       "          [ 1.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "           -1.72938632e-03, -3.98213791e-04,  6.47102431e-03],\n",
       "          [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "           -1.72938632e-03, -3.98213791e-04,  6.47102431e-03],\n",
       "          ...,\n",
       "          [ 6.66000000e+02,  6.66000000e+02,  6.66000000e+02, ...,\n",
       "            6.66000000e+02,  6.66000000e+02,  6.66000000e+02],\n",
       "          [ 6.66000000e+02,  6.66000000e+02,  6.66000000e+02, ...,\n",
       "            6.66000000e+02,  6.66000000e+02,  6.66000000e+02],\n",
       "          [ 6.66000000e+02,  6.66000000e+02,  6.66000000e+02, ...,\n",
       "            6.66000000e+02,  6.66000000e+02,  6.66000000e+02]]]),\n",
       "  'y_train':      individualMRGerm_stac\n",
       "  0                      0.0\n",
       "  1                      0.0\n",
       "  2                      1.0\n",
       "  3                      1.0\n",
       "  4                      1.0\n",
       "  ..                     ...\n",
       "  887                    1.0\n",
       "  888                    1.0\n",
       "  889                    0.0\n",
       "  890                    0.0\n",
       "  891                    1.0\n",
       "  \n",
       "  [892 rows x 1 columns],\n",
       "  'X_val': array([[[0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "           0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "          [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "           0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "          [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "           0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "          ...,\n",
       "          [6.66000000e+02, 6.66000000e+02, 6.66000000e+02, ...,\n",
       "           6.66000000e+02, 6.66000000e+02, 6.66000000e+02],\n",
       "          [6.66000000e+02, 6.66000000e+02, 6.66000000e+02, ...,\n",
       "           6.66000000e+02, 6.66000000e+02, 6.66000000e+02],\n",
       "          [6.66000000e+02, 6.66000000e+02, 6.66000000e+02, ...,\n",
       "           6.66000000e+02, 6.66000000e+02, 6.66000000e+02]],\n",
       "  \n",
       "         [[0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "           0.00000000e+00, 0.00000000e+00, 1.27556831e-02],\n",
       "          [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "           0.00000000e+00, 0.00000000e+00, 1.27556831e-02],\n",
       "          [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "           0.00000000e+00, 0.00000000e+00, 1.27556831e-02],\n",
       "          ...,\n",
       "          [6.66000000e+02, 6.66000000e+02, 6.66000000e+02, ...,\n",
       "           6.66000000e+02, 6.66000000e+02, 6.66000000e+02],\n",
       "          [6.66000000e+02, 6.66000000e+02, 6.66000000e+02, ...,\n",
       "           6.66000000e+02, 6.66000000e+02, 6.66000000e+02],\n",
       "          [6.66000000e+02, 6.66000000e+02, 6.66000000e+02, ...,\n",
       "           6.66000000e+02, 6.66000000e+02, 6.66000000e+02]],\n",
       "  \n",
       "         [[0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "           0.00000000e+00, 0.00000000e+00, 1.27556831e-02],\n",
       "          [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "           0.00000000e+00, 0.00000000e+00, 1.27556831e-02],\n",
       "          [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "           0.00000000e+00, 0.00000000e+00, 1.27556831e-02],\n",
       "          ...,\n",
       "          [6.66000000e+02, 6.66000000e+02, 6.66000000e+02, ...,\n",
       "           6.66000000e+02, 6.66000000e+02, 6.66000000e+02],\n",
       "          [6.66000000e+02, 6.66000000e+02, 6.66000000e+02, ...,\n",
       "           6.66000000e+02, 6.66000000e+02, 6.66000000e+02],\n",
       "          [6.66000000e+02, 6.66000000e+02, 6.66000000e+02, ...,\n",
       "           6.66000000e+02, 6.66000000e+02, 6.66000000e+02]],\n",
       "  \n",
       "         ...,\n",
       "  \n",
       "         [[0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "           0.00000000e+00, 0.00000000e+00, 1.27556831e-02],\n",
       "          [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "           0.00000000e+00, 0.00000000e+00, 1.27556831e-02],\n",
       "          [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "           0.00000000e+00, 0.00000000e+00, 1.27556831e-02],\n",
       "          ...,\n",
       "          [6.66000000e+02, 6.66000000e+02, 6.66000000e+02, ...,\n",
       "           6.66000000e+02, 6.66000000e+02, 6.66000000e+02],\n",
       "          [6.66000000e+02, 6.66000000e+02, 6.66000000e+02, ...,\n",
       "           6.66000000e+02, 6.66000000e+02, 6.66000000e+02],\n",
       "          [6.66000000e+02, 6.66000000e+02, 6.66000000e+02, ...,\n",
       "           6.66000000e+02, 6.66000000e+02, 6.66000000e+02]],\n",
       "  \n",
       "         [[0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "           0.00000000e+00, 0.00000000e+00, 1.27556831e-02],\n",
       "          [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "           0.00000000e+00, 0.00000000e+00, 1.27556831e-02],\n",
       "          [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "           0.00000000e+00, 0.00000000e+00, 1.27556831e-02],\n",
       "          ...,\n",
       "          [6.66000000e+02, 6.66000000e+02, 6.66000000e+02, ...,\n",
       "           6.66000000e+02, 6.66000000e+02, 6.66000000e+02],\n",
       "          [6.66000000e+02, 6.66000000e+02, 6.66000000e+02, ...,\n",
       "           6.66000000e+02, 6.66000000e+02, 6.66000000e+02],\n",
       "          [6.66000000e+02, 6.66000000e+02, 6.66000000e+02, ...,\n",
       "           6.66000000e+02, 6.66000000e+02, 6.66000000e+02]],\n",
       "  \n",
       "         [[0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "           0.00000000e+00, 0.00000000e+00, 1.27556831e-02],\n",
       "          [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "           0.00000000e+00, 0.00000000e+00, 1.27556831e-02],\n",
       "          [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "           0.00000000e+00, 0.00000000e+00, 1.27556831e-02],\n",
       "          ...,\n",
       "          [6.66000000e+02, 6.66000000e+02, 6.66000000e+02, ...,\n",
       "           6.66000000e+02, 6.66000000e+02, 6.66000000e+02],\n",
       "          [6.66000000e+02, 6.66000000e+02, 6.66000000e+02, ...,\n",
       "           6.66000000e+02, 6.66000000e+02, 6.66000000e+02],\n",
       "          [6.66000000e+02, 6.66000000e+02, 6.66000000e+02, ...,\n",
       "           6.66000000e+02, 6.66000000e+02, 6.66000000e+02]]]),\n",
       "  'y_val':      individualMRGerm_stac\n",
       "  0                      0.0\n",
       "  1                      0.0\n",
       "  2                      0.0\n",
       "  3                      0.0\n",
       "  4                      0.0\n",
       "  ..                     ...\n",
       "  345                    0.0\n",
       "  346                    0.0\n",
       "  347                    0.0\n",
       "  348                    0.0\n",
       "  349                    0.0\n",
       "  \n",
       "  [350 rows x 1 columns]},\n",
       " '2': {'dropout': 0.15,\n",
       "  'layers': [80, 50, 1],\n",
       "  'lr_scheduler': 0.01,\n",
       "  'activation': 'tanh',\n",
       "  'X_train': array([[[ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "            1.64366512e-02, -3.23697851e-04, -8.39531042e-05],\n",
       "          [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "            2.86872359e-02, -3.23697851e-04,  6.03732323e-03],\n",
       "          [ 6.66000000e+02,  6.66000000e+02,  6.66000000e+02, ...,\n",
       "            6.66000000e+02,  6.66000000e+02,  6.66000000e+02],\n",
       "          ...,\n",
       "          [ 6.66000000e+02,  6.66000000e+02,  6.66000000e+02, ...,\n",
       "            6.66000000e+02,  6.66000000e+02,  6.66000000e+02],\n",
       "          [ 6.66000000e+02,  6.66000000e+02,  6.66000000e+02, ...,\n",
       "            6.66000000e+02,  6.66000000e+02,  6.66000000e+02],\n",
       "          [ 6.66000000e+02,  6.66000000e+02,  6.66000000e+02, ...,\n",
       "            6.66000000e+02,  6.66000000e+02,  6.66000000e+02]],\n",
       "  \n",
       "         [[ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "           -1.76563737e-03, -3.23697851e-04, -6.20522944e-03],\n",
       "          [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "           -1.76563737e-03, -3.23697851e-04, -6.20522944e-03],\n",
       "          [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "           -1.76563737e-03, -3.23697851e-04, -8.39531042e-05],\n",
       "          ...,\n",
       "          [ 6.66000000e+02,  6.66000000e+02,  6.66000000e+02, ...,\n",
       "            6.66000000e+02,  6.66000000e+02,  6.66000000e+02],\n",
       "          [ 6.66000000e+02,  6.66000000e+02,  6.66000000e+02, ...,\n",
       "            6.66000000e+02,  6.66000000e+02,  6.66000000e+02],\n",
       "          [ 6.66000000e+02,  6.66000000e+02,  6.66000000e+02, ...,\n",
       "            6.66000000e+02,  6.66000000e+02,  6.66000000e+02]],\n",
       "  \n",
       "         [[ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "            1.25454366e-02, -3.23697851e-04,  6.03732323e-03],\n",
       "          [ 0.00000000e+00,  1.00000000e+00,  0.00000000e+00, ...,\n",
       "            3.88083288e-03, -3.23697851e-04,  6.03732323e-03],\n",
       "          [ 6.66000000e+02,  6.66000000e+02,  6.66000000e+02, ...,\n",
       "            6.66000000e+02,  6.66000000e+02,  6.66000000e+02],\n",
       "          ...,\n",
       "          [ 6.66000000e+02,  6.66000000e+02,  6.66000000e+02, ...,\n",
       "            6.66000000e+02,  6.66000000e+02,  6.66000000e+02],\n",
       "          [ 6.66000000e+02,  6.66000000e+02,  6.66000000e+02, ...,\n",
       "            6.66000000e+02,  6.66000000e+02,  6.66000000e+02],\n",
       "          [ 6.66000000e+02,  6.66000000e+02,  6.66000000e+02, ...,\n",
       "            6.66000000e+02,  6.66000000e+02,  6.66000000e+02]],\n",
       "  \n",
       "         ...,\n",
       "  \n",
       "         [[ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "           -1.76563737e-03, -3.23697851e-04, -8.39531042e-05],\n",
       "          [ 0.00000000e+00,  0.00000000e+00,  1.00000000e+00, ...,\n",
       "           -1.76563737e-03, -3.23697851e-04, -8.39531042e-05],\n",
       "          [ 6.66000000e+02,  6.66000000e+02,  6.66000000e+02, ...,\n",
       "            6.66000000e+02,  6.66000000e+02,  6.66000000e+02],\n",
       "          ...,\n",
       "          [ 6.66000000e+02,  6.66000000e+02,  6.66000000e+02, ...,\n",
       "            6.66000000e+02,  6.66000000e+02,  6.66000000e+02],\n",
       "          [ 6.66000000e+02,  6.66000000e+02,  6.66000000e+02, ...,\n",
       "            6.66000000e+02,  6.66000000e+02,  6.66000000e+02],\n",
       "          [ 6.66000000e+02,  6.66000000e+02,  6.66000000e+02, ...,\n",
       "            6.66000000e+02,  6.66000000e+02,  6.66000000e+02]],\n",
       "  \n",
       "         [[ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "           -1.76563737e-03, -3.23697851e-04, -8.39531042e-05],\n",
       "          [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "           -1.76563737e-03, -3.23697851e-04, -8.39531042e-05],\n",
       "          [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "           -1.76563737e-03, -3.23697851e-04,  6.03732323e-03],\n",
       "          ...,\n",
       "          [ 6.66000000e+02,  6.66000000e+02,  6.66000000e+02, ...,\n",
       "            6.66000000e+02,  6.66000000e+02,  6.66000000e+02],\n",
       "          [ 6.66000000e+02,  6.66000000e+02,  6.66000000e+02, ...,\n",
       "            6.66000000e+02,  6.66000000e+02,  6.66000000e+02],\n",
       "          [ 6.66000000e+02,  6.66000000e+02,  6.66000000e+02, ...,\n",
       "            6.66000000e+02,  6.66000000e+02,  6.66000000e+02]],\n",
       "  \n",
       "         [[ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "           -1.76563737e-03, -3.23697851e-04, -8.39531042e-05],\n",
       "          [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "           -1.76563737e-03, -3.23697851e-04, -8.39531042e-05],\n",
       "          [ 6.66000000e+02,  6.66000000e+02,  6.66000000e+02, ...,\n",
       "            6.66000000e+02,  6.66000000e+02,  6.66000000e+02],\n",
       "          ...,\n",
       "          [ 6.66000000e+02,  6.66000000e+02,  6.66000000e+02, ...,\n",
       "            6.66000000e+02,  6.66000000e+02,  6.66000000e+02],\n",
       "          [ 6.66000000e+02,  6.66000000e+02,  6.66000000e+02, ...,\n",
       "            6.66000000e+02,  6.66000000e+02,  6.66000000e+02],\n",
       "          [ 6.66000000e+02,  6.66000000e+02,  6.66000000e+02, ...,\n",
       "            6.66000000e+02,  6.66000000e+02,  6.66000000e+02]]]),\n",
       "  'y_train':      individualMRGerm_stac\n",
       "  0                      1.0\n",
       "  1                      1.0\n",
       "  2                      1.0\n",
       "  3                      1.0\n",
       "  4                      0.0\n",
       "  ..                     ...\n",
       "  887                    0.0\n",
       "  888                    0.0\n",
       "  889                    1.0\n",
       "  890                    0.0\n",
       "  891                    0.0\n",
       "  \n",
       "  [892 rows x 1 columns],\n",
       "  'X_val': array([[[  0.,   0.,   0., ...,   0.,   0.,   0.],\n",
       "          [  0.,   0.,   0., ...,   0.,   0.,   0.],\n",
       "          [  0.,   0.,   0., ...,   0.,   0.,   0.],\n",
       "          ...,\n",
       "          [666., 666., 666., ..., 666., 666., 666.],\n",
       "          [666., 666., 666., ..., 666., 666., 666.],\n",
       "          [666., 666., 666., ..., 666., 666., 666.]],\n",
       "  \n",
       "         [[  0.,   0.,   0., ...,   0.,   0.,   0.],\n",
       "          [  0.,   0.,   0., ...,   0.,   0.,   0.],\n",
       "          [  0.,   0.,   0., ...,   0.,   0.,   0.],\n",
       "          ...,\n",
       "          [666., 666., 666., ..., 666., 666., 666.],\n",
       "          [666., 666., 666., ..., 666., 666., 666.],\n",
       "          [666., 666., 666., ..., 666., 666., 666.]],\n",
       "  \n",
       "         [[  0.,   0.,   0., ...,   0.,   0.,   0.],\n",
       "          [  0.,   0.,   0., ...,   0.,   0.,   0.],\n",
       "          [  0.,   0.,   0., ...,   0.,   0.,   0.],\n",
       "          ...,\n",
       "          [666., 666., 666., ..., 666., 666., 666.],\n",
       "          [666., 666., 666., ..., 666., 666., 666.],\n",
       "          [666., 666., 666., ..., 666., 666., 666.]],\n",
       "  \n",
       "         ...,\n",
       "  \n",
       "         [[  0.,   0.,   0., ...,   0.,   0.,   0.],\n",
       "          [  0.,   0.,   0., ...,   0.,   0.,   0.],\n",
       "          [  0.,   0.,   0., ...,   0.,   0.,   0.],\n",
       "          ...,\n",
       "          [666., 666., 666., ..., 666., 666., 666.],\n",
       "          [666., 666., 666., ..., 666., 666., 666.],\n",
       "          [666., 666., 666., ..., 666., 666., 666.]],\n",
       "  \n",
       "         [[  0.,   0.,   0., ...,   0.,   0.,   0.],\n",
       "          [  0.,   0.,   0., ...,   0.,   0.,   0.],\n",
       "          [  0.,   0.,   0., ...,   0.,   0.,   0.],\n",
       "          ...,\n",
       "          [666., 666., 666., ..., 666., 666., 666.],\n",
       "          [666., 666., 666., ..., 666., 666., 666.],\n",
       "          [666., 666., 666., ..., 666., 666., 666.]],\n",
       "  \n",
       "         [[  0.,   0.,   0., ...,   0.,   0.,   0.],\n",
       "          [  0.,   0.,   0., ...,   0.,   0.,   0.],\n",
       "          [  0.,   0.,   0., ...,   0.,   0.,   0.],\n",
       "          ...,\n",
       "          [666., 666., 666., ..., 666., 666., 666.],\n",
       "          [666., 666., 666., ..., 666., 666., 666.],\n",
       "          [666., 666., 666., ..., 666., 666., 666.]]]),\n",
       "  'y_val':      individualMRGerm_stac\n",
       "  0                      0.0\n",
       "  1                      0.0\n",
       "  2                      0.0\n",
       "  3                      0.0\n",
       "  4                      0.0\n",
       "  ..                     ...\n",
       "  345                    0.0\n",
       "  346                    0.0\n",
       "  347                    0.0\n",
       "  348                    0.0\n",
       "  349                    0.0\n",
       "  \n",
       "  [350 rows x 1 columns]},\n",
       " '3': {'dropout': 0.15,\n",
       "  'layers': [80, 30, 1],\n",
       "  'lr_scheduler': 0.1,\n",
       "  'activation': 'tanh',\n",
       "  'X_train': array([[[ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "           -1.80367267e-03, -4.38927232e-04, -6.58789675e-05],\n",
       "          [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "           -1.80367267e-03, -4.38927232e-04, -6.58789675e-05],\n",
       "          [ 6.66000000e+02,  6.66000000e+02,  6.66000000e+02, ...,\n",
       "            6.66000000e+02,  6.66000000e+02,  6.66000000e+02],\n",
       "          ...,\n",
       "          [ 6.66000000e+02,  6.66000000e+02,  6.66000000e+02, ...,\n",
       "            6.66000000e+02,  6.66000000e+02,  6.66000000e+02],\n",
       "          [ 6.66000000e+02,  6.66000000e+02,  6.66000000e+02, ...,\n",
       "            6.66000000e+02,  6.66000000e+02,  6.66000000e+02],\n",
       "          [ 6.66000000e+02,  6.66000000e+02,  6.66000000e+02, ...,\n",
       "            6.66000000e+02,  6.66000000e+02,  6.66000000e+02]],\n",
       "  \n",
       "         [[ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "            1.24317440e-02, -4.38927232e-04, -6.58789675e-05],\n",
       "          [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "            2.95419616e-02, -4.38927232e-04, -6.58789675e-05],\n",
       "          [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "            2.95419616e-02, -4.38927232e-04, -6.58789675e-05],\n",
       "          ...,\n",
       "          [ 6.66000000e+02,  6.66000000e+02,  6.66000000e+02, ...,\n",
       "            6.66000000e+02,  6.66000000e+02,  6.66000000e+02],\n",
       "          [ 6.66000000e+02,  6.66000000e+02,  6.66000000e+02, ...,\n",
       "            6.66000000e+02,  6.66000000e+02,  6.66000000e+02],\n",
       "          [ 6.66000000e+02,  6.66000000e+02,  6.66000000e+02, ...,\n",
       "            6.66000000e+02,  6.66000000e+02,  6.66000000e+02]],\n",
       "  \n",
       "         [[ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "           -1.80367267e-03, -4.38927232e-04,  6.25059643e-03],\n",
       "          [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "           -1.80367267e-03, -4.38927232e-04,  6.25059643e-03],\n",
       "          [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "           -1.80367267e-03, -4.38927232e-04,  6.25059643e-03],\n",
       "          ...,\n",
       "          [ 6.66000000e+02,  6.66000000e+02,  6.66000000e+02, ...,\n",
       "            6.66000000e+02,  6.66000000e+02,  6.66000000e+02],\n",
       "          [ 6.66000000e+02,  6.66000000e+02,  6.66000000e+02, ...,\n",
       "            6.66000000e+02,  6.66000000e+02,  6.66000000e+02],\n",
       "          [ 6.66000000e+02,  6.66000000e+02,  6.66000000e+02, ...,\n",
       "            6.66000000e+02,  6.66000000e+02,  6.66000000e+02]],\n",
       "  \n",
       "         ...,\n",
       "  \n",
       "         [[ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "           -1.80367267e-03, -4.38927232e-04, -6.58789675e-05],\n",
       "          [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "           -1.80367267e-03, -4.38927232e-04, -6.58789675e-05],\n",
       "          [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "           -1.80367267e-03, -4.38927232e-04, -6.58789675e-05],\n",
       "          ...,\n",
       "          [ 6.66000000e+02,  6.66000000e+02,  6.66000000e+02, ...,\n",
       "            6.66000000e+02,  6.66000000e+02,  6.66000000e+02],\n",
       "          [ 6.66000000e+02,  6.66000000e+02,  6.66000000e+02, ...,\n",
       "            6.66000000e+02,  6.66000000e+02,  6.66000000e+02],\n",
       "          [ 6.66000000e+02,  6.66000000e+02,  6.66000000e+02, ...,\n",
       "            6.66000000e+02,  6.66000000e+02,  6.66000000e+02]],\n",
       "  \n",
       "         [[ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "           -1.80367267e-03, -4.38927232e-04, -6.58789675e-05],\n",
       "          [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "           -1.80367267e-03, -4.38927232e-04, -6.58789675e-05],\n",
       "          [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "           -1.80367267e-03, -4.38927232e-04, -6.58789675e-05],\n",
       "          ...,\n",
       "          [ 6.66000000e+02,  6.66000000e+02,  6.66000000e+02, ...,\n",
       "            6.66000000e+02,  6.66000000e+02,  6.66000000e+02],\n",
       "          [ 6.66000000e+02,  6.66000000e+02,  6.66000000e+02, ...,\n",
       "            6.66000000e+02,  6.66000000e+02,  6.66000000e+02],\n",
       "          [ 6.66000000e+02,  6.66000000e+02,  6.66000000e+02, ...,\n",
       "            6.66000000e+02,  6.66000000e+02,  6.66000000e+02]],\n",
       "  \n",
       "         [[ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "            8.90717409e-03, -4.38927232e-04,  6.25059643e-03],\n",
       "          [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "            2.95419616e-02, -4.38927232e-04, -6.58789675e-05],\n",
       "          [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "            2.95419616e-02, -4.38927232e-04, -6.58789675e-05],\n",
       "          ...,\n",
       "          [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "            2.95419616e-02, -4.38927232e-04, -6.58789675e-05],\n",
       "          [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "            2.95419616e-02, -4.38927232e-04, -6.58789675e-05],\n",
       "          [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "            2.95419616e-02, -4.38927232e-04, -6.58789675e-05]]]),\n",
       "  'y_train':      individualMRGerm_stac\n",
       "  0                      1.0\n",
       "  1                      0.0\n",
       "  2                      0.0\n",
       "  3                      0.0\n",
       "  4                      1.0\n",
       "  ..                     ...\n",
       "  887                    1.0\n",
       "  888                    1.0\n",
       "  889                    1.0\n",
       "  890                    0.0\n",
       "  891                    0.0\n",
       "  \n",
       "  [892 rows x 1 columns],\n",
       "  'X_val': array([[[  0.,   0.,   0., ...,   0.,   0.,   0.],\n",
       "          [  0.,   0.,   0., ...,   0.,   0.,   0.],\n",
       "          [  0.,   0.,   0., ...,   0.,   0.,   0.],\n",
       "          ...,\n",
       "          [666., 666., 666., ..., 666., 666., 666.],\n",
       "          [666., 666., 666., ..., 666., 666., 666.],\n",
       "          [666., 666., 666., ..., 666., 666., 666.]],\n",
       "  \n",
       "         [[  0.,   0.,   0., ...,   0.,   0.,   0.],\n",
       "          [  0.,   0.,   0., ...,   0.,   0.,   0.],\n",
       "          [  0.,   0.,   0., ...,   0.,   0.,   0.],\n",
       "          ...,\n",
       "          [666., 666., 666., ..., 666., 666., 666.],\n",
       "          [666., 666., 666., ..., 666., 666., 666.],\n",
       "          [666., 666., 666., ..., 666., 666., 666.]],\n",
       "  \n",
       "         [[  0.,   0.,   0., ...,   0.,   0.,   0.],\n",
       "          [  0.,   0.,   0., ...,   0.,   0.,   0.],\n",
       "          [  0.,   0.,   0., ...,   0.,   0.,   0.],\n",
       "          ...,\n",
       "          [666., 666., 666., ..., 666., 666., 666.],\n",
       "          [666., 666., 666., ..., 666., 666., 666.],\n",
       "          [666., 666., 666., ..., 666., 666., 666.]],\n",
       "  \n",
       "         ...,\n",
       "  \n",
       "         [[  0.,   0.,   0., ...,   0.,   0.,   0.],\n",
       "          [  0.,   0.,   0., ...,   0.,   0.,   0.],\n",
       "          [  0.,   0.,   0., ...,   0.,   0.,   0.],\n",
       "          ...,\n",
       "          [666., 666., 666., ..., 666., 666., 666.],\n",
       "          [666., 666., 666., ..., 666., 666., 666.],\n",
       "          [666., 666., 666., ..., 666., 666., 666.]],\n",
       "  \n",
       "         [[  0.,   0.,   0., ...,   0.,   0.,   0.],\n",
       "          [  0.,   0.,   0., ...,   0.,   0.,   0.],\n",
       "          [  0.,   0.,   0., ...,   0.,   0.,   0.],\n",
       "          ...,\n",
       "          [666., 666., 666., ..., 666., 666., 666.],\n",
       "          [666., 666., 666., ..., 666., 666., 666.],\n",
       "          [666., 666., 666., ..., 666., 666., 666.]],\n",
       "  \n",
       "         [[  0.,   0.,   0., ...,   0.,   0.,   0.],\n",
       "          [  0.,   0.,   0., ...,   0.,   0.,   0.],\n",
       "          [  0.,   0.,   0., ...,   0.,   0.,   0.],\n",
       "          ...,\n",
       "          [666., 666., 666., ..., 666., 666., 666.],\n",
       "          [666., 666., 666., ..., 666., 666., 666.],\n",
       "          [666., 666., 666., ..., 666., 666., 666.]]]),\n",
       "  'y_val':      individualMRGerm_stac\n",
       "  0                      0.0\n",
       "  1                      0.0\n",
       "  2                      0.0\n",
       "  3                      0.0\n",
       "  4                      0.0\n",
       "  ..                     ...\n",
       "  345                    0.0\n",
       "  346                    0.0\n",
       "  347                    0.0\n",
       "  348                    0.0\n",
       "  349                    0.0\n",
       "  \n",
       "  [350 rows x 1 columns]},\n",
       " '4': {'dropout': 0.3,\n",
       "  'layers': [80, 60, 1],\n",
       "  'lr_scheduler': 0.1,\n",
       "  'activation': 'tanh',\n",
       "  'X_train': array([[[ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "           -1.71412623e-03, -4.39937013e-04, -1.10047912e-04],\n",
       "          [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "           -1.71412623e-03, -4.39937013e-04, -1.10047912e-04],\n",
       "          [ 6.66000000e+02,  6.66000000e+02,  6.66000000e+02, ...,\n",
       "            6.66000000e+02,  6.66000000e+02,  6.66000000e+02],\n",
       "          ...,\n",
       "          [ 6.66000000e+02,  6.66000000e+02,  6.66000000e+02, ...,\n",
       "            6.66000000e+02,  6.66000000e+02,  6.66000000e+02],\n",
       "          [ 6.66000000e+02,  6.66000000e+02,  6.66000000e+02, ...,\n",
       "            6.66000000e+02,  6.66000000e+02,  6.66000000e+02],\n",
       "          [ 6.66000000e+02,  6.66000000e+02,  6.66000000e+02, ...,\n",
       "            6.66000000e+02,  6.66000000e+02,  6.66000000e+02]],\n",
       "  \n",
       "         [[ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "           -1.71412623e-03, -4.39937013e-04,  5.98660643e-03],\n",
       "          [ 6.66000000e+02,  6.66000000e+02,  6.66000000e+02, ...,\n",
       "            6.66000000e+02,  6.66000000e+02,  6.66000000e+02],\n",
       "          [ 6.66000000e+02,  6.66000000e+02,  6.66000000e+02, ...,\n",
       "            6.66000000e+02,  6.66000000e+02,  6.66000000e+02],\n",
       "          ...,\n",
       "          [ 6.66000000e+02,  6.66000000e+02,  6.66000000e+02, ...,\n",
       "            6.66000000e+02,  6.66000000e+02,  6.66000000e+02],\n",
       "          [ 6.66000000e+02,  6.66000000e+02,  6.66000000e+02, ...,\n",
       "            6.66000000e+02,  6.66000000e+02,  6.66000000e+02],\n",
       "          [ 6.66000000e+02,  6.66000000e+02,  6.66000000e+02, ...,\n",
       "            6.66000000e+02,  6.66000000e+02,  6.66000000e+02]],\n",
       "  \n",
       "         [[ 0.00000000e+00,  1.00000000e+00,  0.00000000e+00, ...,\n",
       "           -1.71412623e-03, -4.39937013e-04,  5.98660643e-03],\n",
       "          [ 0.00000000e+00,  1.00000000e+00,  0.00000000e+00, ...,\n",
       "           -1.71412623e-03, -4.39937013e-04,  5.98660643e-03],\n",
       "          [ 0.00000000e+00,  1.00000000e+00,  0.00000000e+00, ...,\n",
       "           -1.71412623e-03, -4.39937013e-04,  5.98660643e-03],\n",
       "          ...,\n",
       "          [ 6.66000000e+02,  6.66000000e+02,  6.66000000e+02, ...,\n",
       "            6.66000000e+02,  6.66000000e+02,  6.66000000e+02],\n",
       "          [ 6.66000000e+02,  6.66000000e+02,  6.66000000e+02, ...,\n",
       "            6.66000000e+02,  6.66000000e+02,  6.66000000e+02],\n",
       "          [ 6.66000000e+02,  6.66000000e+02,  6.66000000e+02, ...,\n",
       "            6.66000000e+02,  6.66000000e+02,  6.66000000e+02]],\n",
       "  \n",
       "         ...,\n",
       "  \n",
       "         [[ 1.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "           -1.71412623e-03, -4.39937013e-04, -1.10047912e-04],\n",
       "          [ 1.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "           -1.71412623e-03, -4.39937013e-04, -1.10047912e-04],\n",
       "          [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "           -1.71412623e-03, -4.39937013e-04, -1.10047912e-04],\n",
       "          ...,\n",
       "          [ 6.66000000e+02,  6.66000000e+02,  6.66000000e+02, ...,\n",
       "            6.66000000e+02,  6.66000000e+02,  6.66000000e+02],\n",
       "          [ 6.66000000e+02,  6.66000000e+02,  6.66000000e+02, ...,\n",
       "            6.66000000e+02,  6.66000000e+02,  6.66000000e+02],\n",
       "          [ 6.66000000e+02,  6.66000000e+02,  6.66000000e+02, ...,\n",
       "            6.66000000e+02,  6.66000000e+02,  6.66000000e+02]],\n",
       "  \n",
       "         [[ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "           -1.71412623e-03, -4.39937013e-04,  5.98660643e-03],\n",
       "          [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "           -1.71412623e-03, -4.39937013e-04,  5.98660643e-03],\n",
       "          [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "           -1.71412623e-03, -4.39937013e-04,  5.98660643e-03],\n",
       "          ...,\n",
       "          [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "           -1.71412623e-03, -4.39937013e-04,  5.98660643e-03],\n",
       "          [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "           -1.71412623e-03, -4.39937013e-04,  5.98660643e-03],\n",
       "          [ 6.66000000e+02,  6.66000000e+02,  6.66000000e+02, ...,\n",
       "            6.66000000e+02,  6.66000000e+02,  6.66000000e+02]],\n",
       "  \n",
       "         [[ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "           -1.71412623e-03, -4.39937013e-04, -1.10047912e-04],\n",
       "          [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "           -1.71412623e-03, -4.39937013e-04, -1.10047912e-04],\n",
       "          [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "           -1.71412623e-03, -4.39937013e-04, -1.10047912e-04],\n",
       "          ...,\n",
       "          [ 6.66000000e+02,  6.66000000e+02,  6.66000000e+02, ...,\n",
       "            6.66000000e+02,  6.66000000e+02,  6.66000000e+02],\n",
       "          [ 6.66000000e+02,  6.66000000e+02,  6.66000000e+02, ...,\n",
       "            6.66000000e+02,  6.66000000e+02,  6.66000000e+02],\n",
       "          [ 6.66000000e+02,  6.66000000e+02,  6.66000000e+02, ...,\n",
       "            6.66000000e+02,  6.66000000e+02,  6.66000000e+02]]]),\n",
       "  'y_train':      individualMRGerm_stac\n",
       "  0                      1.0\n",
       "  1                      1.0\n",
       "  2                      1.0\n",
       "  3                      1.0\n",
       "  4                      1.0\n",
       "  ..                     ...\n",
       "  887                    1.0\n",
       "  888                    0.0\n",
       "  889                    0.0\n",
       "  890                    0.0\n",
       "  891                    1.0\n",
       "  \n",
       "  [892 rows x 1 columns],\n",
       "  'X_val': array([[[  0.,   0.,   0., ...,   0.,   0.,   0.],\n",
       "          [  0.,   0.,   0., ...,   0.,   0.,   0.],\n",
       "          [  0.,   0.,   0., ...,   0.,   0.,   0.],\n",
       "          ...,\n",
       "          [666., 666., 666., ..., 666., 666., 666.],\n",
       "          [666., 666., 666., ..., 666., 666., 666.],\n",
       "          [666., 666., 666., ..., 666., 666., 666.]],\n",
       "  \n",
       "         [[  0.,   0.,   0., ...,   0.,   0.,   0.],\n",
       "          [  0.,   0.,   0., ...,   0.,   0.,   0.],\n",
       "          [  0.,   0.,   0., ...,   0.,   0.,   0.],\n",
       "          ...,\n",
       "          [666., 666., 666., ..., 666., 666., 666.],\n",
       "          [666., 666., 666., ..., 666., 666., 666.],\n",
       "          [666., 666., 666., ..., 666., 666., 666.]],\n",
       "  \n",
       "         [[  0.,   0.,   0., ...,   0.,   0.,   0.],\n",
       "          [  0.,   0.,   0., ...,   0.,   0.,   0.],\n",
       "          [  0.,   0.,   0., ...,   0.,   0.,   0.],\n",
       "          ...,\n",
       "          [666., 666., 666., ..., 666., 666., 666.],\n",
       "          [666., 666., 666., ..., 666., 666., 666.],\n",
       "          [666., 666., 666., ..., 666., 666., 666.]],\n",
       "  \n",
       "         ...,\n",
       "  \n",
       "         [[  0.,   0.,   0., ...,   0.,   0.,   0.],\n",
       "          [  0.,   0.,   0., ...,   0.,   0.,   0.],\n",
       "          [  0.,   0.,   0., ...,   0.,   0.,   0.],\n",
       "          ...,\n",
       "          [666., 666., 666., ..., 666., 666., 666.],\n",
       "          [666., 666., 666., ..., 666., 666., 666.],\n",
       "          [666., 666., 666., ..., 666., 666., 666.]],\n",
       "  \n",
       "         [[  0.,   0.,   0., ...,   0.,   0.,   0.],\n",
       "          [  0.,   0.,   0., ...,   0.,   0.,   0.],\n",
       "          [  0.,   0.,   0., ...,   0.,   0.,   0.],\n",
       "          ...,\n",
       "          [666., 666., 666., ..., 666., 666., 666.],\n",
       "          [666., 666., 666., ..., 666., 666., 666.],\n",
       "          [666., 666., 666., ..., 666., 666., 666.]],\n",
       "  \n",
       "         [[  0.,   0.,   0., ...,   0.,   0.,   0.],\n",
       "          [  0.,   0.,   0., ...,   0.,   0.,   0.],\n",
       "          [  0.,   0.,   0., ...,   0.,   0.,   0.],\n",
       "          ...,\n",
       "          [666., 666., 666., ..., 666., 666., 666.],\n",
       "          [666., 666., 666., ..., 666., 666., 666.],\n",
       "          [666., 666., 666., ..., 666., 666., 666.]]]),\n",
       "  'y_val':      individualMRGerm_stac\n",
       "  0                      0.0\n",
       "  1                      0.0\n",
       "  2                      0.0\n",
       "  3                      0.0\n",
       "  4                      0.0\n",
       "  ..                     ...\n",
       "  345                    0.0\n",
       "  346                    0.0\n",
       "  347                    0.0\n",
       "  348                    0.0\n",
       "  349                    0.0\n",
       "  \n",
       "  [350 rows x 1 columns]},\n",
       " '5': {'dropout': 0.0,\n",
       "  'layers': [80, 50, 1],\n",
       "  'lr_scheduler': 0.1,\n",
       "  'activation': 'LeakyReLU',\n",
       "  'X_train': array([[[ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "           -1.93986824e-03, -3.06483742e-04,  6.33807315e-03],\n",
       "          [ 6.66000000e+02,  6.66000000e+02,  6.66000000e+02, ...,\n",
       "            6.66000000e+02,  6.66000000e+02,  6.66000000e+02],\n",
       "          [ 6.66000000e+02,  6.66000000e+02,  6.66000000e+02, ...,\n",
       "            6.66000000e+02,  6.66000000e+02,  6.66000000e+02],\n",
       "          ...,\n",
       "          [ 6.66000000e+02,  6.66000000e+02,  6.66000000e+02, ...,\n",
       "            6.66000000e+02,  6.66000000e+02,  6.66000000e+02],\n",
       "          [ 6.66000000e+02,  6.66000000e+02,  6.66000000e+02, ...,\n",
       "            6.66000000e+02,  6.66000000e+02,  6.66000000e+02],\n",
       "          [ 6.66000000e+02,  6.66000000e+02,  6.66000000e+02, ...,\n",
       "            6.66000000e+02,  6.66000000e+02,  6.66000000e+02]],\n",
       "  \n",
       "         [[ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "           -1.93986824e-03, -3.06483742e-04,  4.96355126e-05],\n",
       "          [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "           -1.93986824e-03, -3.06483742e-04,  4.96355126e-05],\n",
       "          [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "           -1.93986824e-03, -3.06483742e-04,  4.96355126e-05],\n",
       "          ...,\n",
       "          [ 6.66000000e+02,  6.66000000e+02,  6.66000000e+02, ...,\n",
       "            6.66000000e+02,  6.66000000e+02,  6.66000000e+02],\n",
       "          [ 6.66000000e+02,  6.66000000e+02,  6.66000000e+02, ...,\n",
       "            6.66000000e+02,  6.66000000e+02,  6.66000000e+02],\n",
       "          [ 6.66000000e+02,  6.66000000e+02,  6.66000000e+02, ...,\n",
       "            6.66000000e+02,  6.66000000e+02,  6.66000000e+02]],\n",
       "  \n",
       "         [[ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "           -1.93986824e-03, -3.06483742e-04,  4.96355126e-05],\n",
       "          [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "           -1.93986824e-03, -3.06483742e-04,  4.96355126e-05],\n",
       "          [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "           -1.93986824e-03, -3.06483742e-04,  4.96355126e-05],\n",
       "          ...,\n",
       "          [ 6.66000000e+02,  6.66000000e+02,  6.66000000e+02, ...,\n",
       "            6.66000000e+02,  6.66000000e+02,  6.66000000e+02],\n",
       "          [ 6.66000000e+02,  6.66000000e+02,  6.66000000e+02, ...,\n",
       "            6.66000000e+02,  6.66000000e+02,  6.66000000e+02],\n",
       "          [ 6.66000000e+02,  6.66000000e+02,  6.66000000e+02, ...,\n",
       "            6.66000000e+02,  6.66000000e+02,  6.66000000e+02]],\n",
       "  \n",
       "         ...,\n",
       "  \n",
       "         [[ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "           -1.93986824e-03, -3.06483742e-04,  4.96355126e-05],\n",
       "          [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "           -1.93986824e-03, -3.06483742e-04,  4.96355126e-05],\n",
       "          [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "           -1.93986824e-03, -3.06483742e-04,  4.96355126e-05],\n",
       "          ...,\n",
       "          [ 6.66000000e+02,  6.66000000e+02,  6.66000000e+02, ...,\n",
       "            6.66000000e+02,  6.66000000e+02,  6.66000000e+02],\n",
       "          [ 6.66000000e+02,  6.66000000e+02,  6.66000000e+02, ...,\n",
       "            6.66000000e+02,  6.66000000e+02,  6.66000000e+02],\n",
       "          [ 6.66000000e+02,  6.66000000e+02,  6.66000000e+02, ...,\n",
       "            6.66000000e+02,  6.66000000e+02,  6.66000000e+02]],\n",
       "  \n",
       "         [[ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "           -1.93986824e-03, -3.06483742e-04,  6.33807315e-03],\n",
       "          [ 6.66000000e+02,  6.66000000e+02,  6.66000000e+02, ...,\n",
       "            6.66000000e+02,  6.66000000e+02,  6.66000000e+02],\n",
       "          [ 6.66000000e+02,  6.66000000e+02,  6.66000000e+02, ...,\n",
       "            6.66000000e+02,  6.66000000e+02,  6.66000000e+02],\n",
       "          ...,\n",
       "          [ 6.66000000e+02,  6.66000000e+02,  6.66000000e+02, ...,\n",
       "            6.66000000e+02,  6.66000000e+02,  6.66000000e+02],\n",
       "          [ 6.66000000e+02,  6.66000000e+02,  6.66000000e+02, ...,\n",
       "            6.66000000e+02,  6.66000000e+02,  6.66000000e+02],\n",
       "          [ 6.66000000e+02,  6.66000000e+02,  6.66000000e+02, ...,\n",
       "            6.66000000e+02,  6.66000000e+02,  6.66000000e+02]],\n",
       "  \n",
       "         [[ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "           -1.93986824e-03, -3.06483742e-04, -6.23880213e-03],\n",
       "          [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "           -1.93986824e-03, -3.06483742e-04, -6.23880213e-03],\n",
       "          [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "           -1.93986824e-03, -3.06483742e-04, -6.23880213e-03],\n",
       "          ...,\n",
       "          [ 6.66000000e+02,  6.66000000e+02,  6.66000000e+02, ...,\n",
       "            6.66000000e+02,  6.66000000e+02,  6.66000000e+02],\n",
       "          [ 6.66000000e+02,  6.66000000e+02,  6.66000000e+02, ...,\n",
       "            6.66000000e+02,  6.66000000e+02,  6.66000000e+02],\n",
       "          [ 6.66000000e+02,  6.66000000e+02,  6.66000000e+02, ...,\n",
       "            6.66000000e+02,  6.66000000e+02,  6.66000000e+02]]]),\n",
       "  'y_train':      individualMRGerm_stac\n",
       "  0                      1.0\n",
       "  1                      0.0\n",
       "  2                      1.0\n",
       "  3                      0.0\n",
       "  4                      1.0\n",
       "  ..                     ...\n",
       "  887                    1.0\n",
       "  888                    0.0\n",
       "  889                    0.0\n",
       "  890                    1.0\n",
       "  891                    0.0\n",
       "  \n",
       "  [892 rows x 1 columns],\n",
       "  'X_val': array([[[0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "           0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "          [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "           0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "          [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "           0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "          ...,\n",
       "          [6.66000000e+02, 6.66000000e+02, 6.66000000e+02, ...,\n",
       "           6.66000000e+02, 6.66000000e+02, 6.66000000e+02],\n",
       "          [6.66000000e+02, 6.66000000e+02, 6.66000000e+02, ...,\n",
       "           6.66000000e+02, 6.66000000e+02, 6.66000000e+02],\n",
       "          [6.66000000e+02, 6.66000000e+02, 6.66000000e+02, ...,\n",
       "           6.66000000e+02, 6.66000000e+02, 6.66000000e+02]],\n",
       "  \n",
       "         [[0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "           0.00000000e+00, 0.00000000e+00, 1.25768753e-02],\n",
       "          [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "           0.00000000e+00, 0.00000000e+00, 1.25768753e-02],\n",
       "          [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "           0.00000000e+00, 0.00000000e+00, 1.25768753e-02],\n",
       "          ...,\n",
       "          [6.66000000e+02, 6.66000000e+02, 6.66000000e+02, ...,\n",
       "           6.66000000e+02, 6.66000000e+02, 6.66000000e+02],\n",
       "          [6.66000000e+02, 6.66000000e+02, 6.66000000e+02, ...,\n",
       "           6.66000000e+02, 6.66000000e+02, 6.66000000e+02],\n",
       "          [6.66000000e+02, 6.66000000e+02, 6.66000000e+02, ...,\n",
       "           6.66000000e+02, 6.66000000e+02, 6.66000000e+02]],\n",
       "  \n",
       "         [[0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "           0.00000000e+00, 0.00000000e+00, 1.25768753e-02],\n",
       "          [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "           0.00000000e+00, 0.00000000e+00, 1.25768753e-02],\n",
       "          [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "           0.00000000e+00, 0.00000000e+00, 1.25768753e-02],\n",
       "          ...,\n",
       "          [6.66000000e+02, 6.66000000e+02, 6.66000000e+02, ...,\n",
       "           6.66000000e+02, 6.66000000e+02, 6.66000000e+02],\n",
       "          [6.66000000e+02, 6.66000000e+02, 6.66000000e+02, ...,\n",
       "           6.66000000e+02, 6.66000000e+02, 6.66000000e+02],\n",
       "          [6.66000000e+02, 6.66000000e+02, 6.66000000e+02, ...,\n",
       "           6.66000000e+02, 6.66000000e+02, 6.66000000e+02]],\n",
       "  \n",
       "         ...,\n",
       "  \n",
       "         [[0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "           0.00000000e+00, 0.00000000e+00, 1.25768753e-02],\n",
       "          [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "           0.00000000e+00, 0.00000000e+00, 1.25768753e-02],\n",
       "          [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "           0.00000000e+00, 0.00000000e+00, 1.25768753e-02],\n",
       "          ...,\n",
       "          [6.66000000e+02, 6.66000000e+02, 6.66000000e+02, ...,\n",
       "           6.66000000e+02, 6.66000000e+02, 6.66000000e+02],\n",
       "          [6.66000000e+02, 6.66000000e+02, 6.66000000e+02, ...,\n",
       "           6.66000000e+02, 6.66000000e+02, 6.66000000e+02],\n",
       "          [6.66000000e+02, 6.66000000e+02, 6.66000000e+02, ...,\n",
       "           6.66000000e+02, 6.66000000e+02, 6.66000000e+02]],\n",
       "  \n",
       "         [[0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "           0.00000000e+00, 0.00000000e+00, 1.25768753e-02],\n",
       "          [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "           0.00000000e+00, 0.00000000e+00, 1.25768753e-02],\n",
       "          [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "           0.00000000e+00, 0.00000000e+00, 1.25768753e-02],\n",
       "          ...,\n",
       "          [6.66000000e+02, 6.66000000e+02, 6.66000000e+02, ...,\n",
       "           6.66000000e+02, 6.66000000e+02, 6.66000000e+02],\n",
       "          [6.66000000e+02, 6.66000000e+02, 6.66000000e+02, ...,\n",
       "           6.66000000e+02, 6.66000000e+02, 6.66000000e+02],\n",
       "          [6.66000000e+02, 6.66000000e+02, 6.66000000e+02, ...,\n",
       "           6.66000000e+02, 6.66000000e+02, 6.66000000e+02]],\n",
       "  \n",
       "         [[0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "           0.00000000e+00, 0.00000000e+00, 1.25768753e-02],\n",
       "          [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "           0.00000000e+00, 0.00000000e+00, 1.25768753e-02],\n",
       "          [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "           0.00000000e+00, 0.00000000e+00, 1.25768753e-02],\n",
       "          ...,\n",
       "          [6.66000000e+02, 6.66000000e+02, 6.66000000e+02, ...,\n",
       "           6.66000000e+02, 6.66000000e+02, 6.66000000e+02],\n",
       "          [6.66000000e+02, 6.66000000e+02, 6.66000000e+02, ...,\n",
       "           6.66000000e+02, 6.66000000e+02, 6.66000000e+02],\n",
       "          [6.66000000e+02, 6.66000000e+02, 6.66000000e+02, ...,\n",
       "           6.66000000e+02, 6.66000000e+02, 6.66000000e+02]]]),\n",
       "  'y_val':      individualMRGerm_stac\n",
       "  0                      0.0\n",
       "  1                      0.0\n",
       "  2                      0.0\n",
       "  3                      0.0\n",
       "  4                      0.0\n",
       "  ..                     ...\n",
       "  345                    0.0\n",
       "  346                    0.0\n",
       "  347                    0.0\n",
       "  348                    0.0\n",
       "  349                    0.0\n",
       "  \n",
       "  [350 rows x 1 columns]}}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bestHyperparameters_bySplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, roc_auc_score\n",
    "\n",
    "def get_metrics_over_time(n_time_steps, y_test_df, y_pred_df):\n",
    "    \"\"\"\n",
    "    Calculate metrics per time step.\n",
    "    Args:\n",
    "        - n_time_steps: Number of time steps.\n",
    "        - y_test_df : DataFrame containing the real values.\n",
    "        - y_pred_df : DataFrame containing the predicted values.\n",
    "    Returns:\n",
    "        - metrics_df: DataFrame containing the metrics for each time step.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Lists to store the metrics\n",
    "    tn_list = []\n",
    "    fp_list = []\n",
    "    fn_list = []\n",
    "    tp_list = []\n",
    "    specificity_list = []\n",
    "    recall_list = []\n",
    "    roc_auc_list = []\n",
    "\n",
    "    # Calculate the metrics for each time step\n",
    "    for t in range(n_time_steps):\n",
    "        y_test_valid = y_test_df\n",
    "        y_pred_valid = y_pred_df\n",
    "\n",
    "        # Round the predictions\n",
    "        y_pred_rounded = np.round(y_pred_valid)\n",
    "\n",
    "        # Calculate the confusion matrix\n",
    "        tn, fp, fn, tp = confusion_matrix(y_test_valid, y_pred_rounded, labels=[0, 1]).ravel()\n",
    "\n",
    "        # Calculate specifciity and recall\n",
    "        specificity = tn / (tn + fp) if (tn + fp) > 0 else np.nan\n",
    "        recall = tp / (tp + fn) if (tp + fn) > 0 else np.nan\n",
    "\n",
    "        # Calculate ROC-AUC\n",
    "        roc = roc_auc_score(y_test_valid, y_pred_valid) if len(np.unique(y_test_valid)) > 1 else np.nan\n",
    "\n",
    "        tn_list.append(tn)\n",
    "        fp_list.append(fp)\n",
    "        fn_list.append(fn)\n",
    "        tp_list.append(tp)\n",
    "        specificity_list.append(specificity)\n",
    "        recall_list.append(recall)\n",
    "        roc_auc_list.append(roc)\n",
    "\n",
    "    # Dataframe to store the metrics per time step\n",
    "    metrics_df = pd.DataFrame({\n",
    "        'Time Step': range(1, n_time_steps+1),\n",
    "        'TN': tn_list,\n",
    "        'FP': fp_list,\n",
    "        'FN': fn_list,\n",
    "        'TP': tp_list,\n",
    "        'Specificity': specificity_list,\n",
    "        'Recall': recall_list,\n",
    "        'ROC AUC': roc_auc_list\n",
    "    })\n",
    "\n",
    "    return metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = './Results_GRU'\n",
    "def load_from_pickle(filename):\n",
    "    with open(filename, 'rb') as f:\n",
    "        return pickle.load(f)\n",
    "\n",
    "    \n",
    "y_pred_by_split = {}\n",
    "y_pred_by_split['1'] = load_from_pickle(os.path.join('./Results_GRU/split_1', \"y_pred_split_1.pkl\"))\n",
    "y_pred_by_split['2'] = load_from_pickle(os.path.join('./Results_GRU/split_2', \"y_pred_split_2.pkl\"))\n",
    "y_pred_by_split['3'] = load_from_pickle(os.path.join('./Results_GRU/split_3', \"y_pred_split_3.pkl\"))\n",
    "y_pred_by_split['4'] = load_from_pickle(os.path.join('./Results_GRU/split_4', \"y_pred_split_4.pkl\"))\n",
    "y_pred_by_split['5'] = load_from_pickle(os.path.join('./Results_GRU/split_5', \"y_pred_split_5.pkl\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_metrics = []\n",
    "\n",
    "for i in [1,2,3,4,5]: \n",
    "    y_test = pd.read_csv(\"../DATA/s\" + str(i) + \"/y_test_normPower2\" + \".csv\")\n",
    "    y_test = y_test[['individualMRGerm_stac']]\n",
    "    y_test = y_test.iloc[0:y_test.shape[0]:hyperparameters[\"n_time_steps\"]].reset_index(drop=True)\n",
    "    \n",
    "    y_pred = y_pred_by_split[str(i)].squeeze()\n",
    "    y_pred_df = pd.DataFrame(y_pred)\n",
    "\n",
    "    df_metrics = get_metrics_over_time(n_time_steps, y_test, y_pred_df)\n",
    "    all_metrics.append(df_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[    Time Step   TN  FP  FN  TP  Specificity    Recall   ROC AUC\n",
       " 0           1  278  19  22  31     0.936027  0.584906  0.817674\n",
       " 1           2  278  19  22  31     0.936027  0.584906  0.817674\n",
       " 2           3  278  19  22  31     0.936027  0.584906  0.817674\n",
       " 3           4  278  19  22  31     0.936027  0.584906  0.817674\n",
       " 4           5  278  19  22  31     0.936027  0.584906  0.817674\n",
       " 5           6  278  19  22  31     0.936027  0.584906  0.817674\n",
       " 6           7  278  19  22  31     0.936027  0.584906  0.817674\n",
       " 7           8  278  19  22  31     0.936027  0.584906  0.817674\n",
       " 8           9  278  19  22  31     0.936027  0.584906  0.817674\n",
       " 9          10  278  19  22  31     0.936027  0.584906  0.817674\n",
       " 10         11  278  19  22  31     0.936027  0.584906  0.817674\n",
       " 11         12  278  19  22  31     0.936027  0.584906  0.817674\n",
       " 12         13  278  19  22  31     0.936027  0.584906  0.817674\n",
       " 13         14  278  19  22  31     0.936027  0.584906  0.817674,\n",
       "     Time Step   TN  FP  FN  TP  Specificity    Recall   ROC AUC\n",
       " 0           1  279  18  20  33     0.939394  0.622642  0.860428\n",
       " 1           2  279  18  20  33     0.939394  0.622642  0.860428\n",
       " 2           3  279  18  20  33     0.939394  0.622642  0.860428\n",
       " 3           4  279  18  20  33     0.939394  0.622642  0.860428\n",
       " 4           5  279  18  20  33     0.939394  0.622642  0.860428\n",
       " 5           6  279  18  20  33     0.939394  0.622642  0.860428\n",
       " 6           7  279  18  20  33     0.939394  0.622642  0.860428\n",
       " 7           8  279  18  20  33     0.939394  0.622642  0.860428\n",
       " 8           9  279  18  20  33     0.939394  0.622642  0.860428\n",
       " 9          10  279  18  20  33     0.939394  0.622642  0.860428\n",
       " 10         11  279  18  20  33     0.939394  0.622642  0.860428\n",
       " 11         12  279  18  20  33     0.939394  0.622642  0.860428\n",
       " 12         13  279  18  20  33     0.939394  0.622642  0.860428\n",
       " 13         14  279  18  20  33     0.939394  0.622642  0.860428,\n",
       "     Time Step   TN  FP  FN  TP  Specificity    Recall   ROC AUC\n",
       " 0           1  274  23  27  26     0.922559  0.490566  0.853948\n",
       " 1           2  274  23  27  26     0.922559  0.490566  0.853948\n",
       " 2           3  274  23  27  26     0.922559  0.490566  0.853948\n",
       " 3           4  274  23  27  26     0.922559  0.490566  0.853948\n",
       " 4           5  274  23  27  26     0.922559  0.490566  0.853948\n",
       " 5           6  274  23  27  26     0.922559  0.490566  0.853948\n",
       " 6           7  274  23  27  26     0.922559  0.490566  0.853948\n",
       " 7           8  274  23  27  26     0.922559  0.490566  0.853948\n",
       " 8           9  274  23  27  26     0.922559  0.490566  0.853948\n",
       " 9          10  274  23  27  26     0.922559  0.490566  0.853948\n",
       " 10         11  274  23  27  26     0.922559  0.490566  0.853948\n",
       " 11         12  274  23  27  26     0.922559  0.490566  0.853948\n",
       " 12         13  274  23  27  26     0.922559  0.490566  0.853948\n",
       " 13         14  274  23  27  26     0.922559  0.490566  0.853948,\n",
       "     Time Step   TN  FP  FN  TP  Specificity    Recall   ROC AUC\n",
       " 0           1  275  22  21  32     0.925926  0.603774  0.858522\n",
       " 1           2  275  22  21  32     0.925926  0.603774  0.858522\n",
       " 2           3  275  22  21  32     0.925926  0.603774  0.858522\n",
       " 3           4  275  22  21  32     0.925926  0.603774  0.858522\n",
       " 4           5  275  22  21  32     0.925926  0.603774  0.858522\n",
       " 5           6  275  22  21  32     0.925926  0.603774  0.858522\n",
       " 6           7  275  22  21  32     0.925926  0.603774  0.858522\n",
       " 7           8  275  22  21  32     0.925926  0.603774  0.858522\n",
       " 8           9  275  22  21  32     0.925926  0.603774  0.858522\n",
       " 9          10  275  22  21  32     0.925926  0.603774  0.858522\n",
       " 10         11  275  22  21  32     0.925926  0.603774  0.858522\n",
       " 11         12  275  22  21  32     0.925926  0.603774  0.858522\n",
       " 12         13  275  22  21  32     0.925926  0.603774  0.858522\n",
       " 13         14  275  22  21  32     0.925926  0.603774  0.858522,\n",
       "     Time Step   TN  FP  FN  TP  Specificity    Recall  ROC AUC\n",
       " 0           1  283  14  26  27     0.952862  0.509434  0.84569\n",
       " 1           2  283  14  26  27     0.952862  0.509434  0.84569\n",
       " 2           3  283  14  26  27     0.952862  0.509434  0.84569\n",
       " 3           4  283  14  26  27     0.952862  0.509434  0.84569\n",
       " 4           5  283  14  26  27     0.952862  0.509434  0.84569\n",
       " 5           6  283  14  26  27     0.952862  0.509434  0.84569\n",
       " 6           7  283  14  26  27     0.952862  0.509434  0.84569\n",
       " 7           8  283  14  26  27     0.952862  0.509434  0.84569\n",
       " 8           9  283  14  26  27     0.952862  0.509434  0.84569\n",
       " 9          10  283  14  26  27     0.952862  0.509434  0.84569\n",
       " 10         11  283  14  26  27     0.952862  0.509434  0.84569\n",
       " 11         12  283  14  26  27     0.952862  0.509434  0.84569\n",
       " 12         13  283  14  26  27     0.952862  0.509434  0.84569\n",
       " 13         14  283  14  26  27     0.952862  0.509434  0.84569]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def myCVGrid(hyperparameters, dropout, lr_scheduler, layers, seed):\n",
    "    \"\"\"Grid Search. Calculate metricDev based on the evaluation. Compares the metricDev with the current bestMetricDev. \n",
    "       If better, updates bestMetricDev and stores those hyperparameters in bestHyperparameters.\n",
    "       \n",
    "       Returns:\n",
    "          - bestHyperparameters (dict)\n",
    "          - X_train, X_val, y_train, y_val (arrays): Training and validation datasets.\n",
    "          - v_early (list): Early stopping information for each hyperparameter combination.\n",
    "          - v_hist (list): Training history for each hyperparameter combination.\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"\\tEntra en validacin...\")\n",
    "    bestHyperparameters = {'dropout': -1, 'layers': -1, 'lr_scheduler':-1}\n",
    "    bestHyperparameters = {'dropout': -1, 'layers': -1, 'lr_scheduler':-1}\n",
    "    bestMetricDev = np.inf\n",
    "\n",
    "    for k in range(len(dropout)):\n",
    "        for l in range(len(layers)):\n",
    "            for m in range(len(lr_scheduler)):\n",
    "                hyperparameters = {\n",
    "                    'n_time_steps': hyperparameters[\"n_time_steps\"],\n",
    "                    'mask_value': hyperparameters[\"mask_value\"],\n",
    "\n",
    "                    'cost_max': hyperparameters[\"cost_max\"],\n",
    "                    'cost_start': hyperparameters[\"cost_start\"],\n",
    "                    'length_infection': hyperparameters[\"length_infection\"],\n",
    "                    'length_start': hyperparameters[\"length_start\"],\n",
    "                    'thresh_after_AMR': hyperparameters[\"thresh_after_AMR\"],\n",
    "                    'thresh_AMR_far': hyperparameters[\"thresh_AMR_far\"],\n",
    "                    \n",
    "                    'batch_size': hyperparameters[\"batch_size\"],\n",
    "                    'n_epochs_max': hyperparameters[\"n_epochs_max\"],\n",
    "                    'monitor':  hyperparameters[\"monitor\"],\n",
    "                    \"mindelta\": hyperparameters[\"mindelta\"],\n",
    "                    \"patience\": hyperparameters[\"patience\"],\n",
    "                    \n",
    "                    \"dropout\":dropout[k],\n",
    "                    \"layers\":layers[l],\n",
    "                    \"lr_scheduler\":lr_scheduler[m],\n",
    "                    \n",
    "                    'kfold': hyperparameters[\"kfold\"],\n",
    "                    \"level\": 3, \n",
    "                    'verbose': 0\n",
    "                }\n",
    "                v_early = []\n",
    "                v_metric_dev = []\n",
    "                v_hist = []\n",
    "                v_val_loss = []\n",
    "                print(\"\\t\\tLearning rate:\", lr_scheduler[m], \", dropout:\", dropout[k], \", layers:\", layers[l])\n",
    "\n",
    "                #Load Train and Validation\n",
    "                X_train = np.load(\"../DATA/s\" + str(i) + \"/X_train_tensor_normPower2\" + \".npy\")\n",
    "                X_val = np.load(\"../DATA/s\" + str(i) + \"/X_val_tensor_normPower2\" + \".npy\")\n",
    "\n",
    "                y_train = pd.read_csv(\"../DATA/s\" + str(i) + \"/y_train_normPower2\" + \".csv\")\n",
    "                y_train = y_train[['individualMRGerm_stac']]\n",
    "                y_train = y_train.iloc[0:y_train.shape[0]:hyperparameters[\"n_time_steps\"]].reset_index(drop=True)\n",
    "\n",
    "                y_val = pd.read_csv(\"../DATA/s\" + str(i) + \"/y_val_normPower2\" + \".csv\")\n",
    "                y_val = y_val[['individualMRGerm_stac']]\n",
    "                y_val = y_val.iloc[0:y_train.shape[0]:hyperparameters[\"n_time_steps\"]].reset_index(drop=True)\n",
    "\n",
    "\n",
    "                # Reset Keras\n",
    "                reset_keras()\n",
    "                gpu_options = tf.compat.v1.GPUOptions(per_process_gpu_memory_fraction=0.2)\n",
    "                sess = tf.compat.v1.Session(config=tf.compat.v1.ConfigProto(gpu_options=gpu_options))\n",
    "                \n",
    "                model, hist, early = run_network(\n",
    "                    X_train, X_val,\n",
    "                    y_train,\n",
    "                    y_val,\n",
    "                    hyperparameters,\n",
    "                    seed\n",
    "                )\n",
    "\n",
    "                v_early.append(early)\n",
    "                v_hist.append(hist)\n",
    "                v_val_loss.append(np.min(hist.history[\"val_loss\"]))\n",
    "            metric_dev = np.mean(v_val_loss)\n",
    "\n",
    "            if metric_dev < bestMetricDev:\n",
    "                print(\"\\t\\t\\tCambio the best\", bestMetricDev, \"por metric dev:\", metric_dev)\n",
    "                bestMetricDev = metric_dev\n",
    "                bestHyperparameters['dropout'] = k\n",
    "                bestHyperparameters['layers'] = l\n",
    "                bestHyperparameters['lr_scheduler'] = m\n",
    "            f = open(\"0_trazas_GRU.txt\", \"a\")\n",
    "            f.write(\"Executed in val :\" + \"con dropout\" + str(dropout[k]) + \"layers\" + str(layers[l]) + \n",
    "                    \"lr_sch\" + str(lr_scheduler[m]) + \" y coste medio en val \" + str(metric_dev) + \"\\n\")\n",
    "            f.close()\n",
    "    f = open(\"0_trazas_GRU.txt\", \"a\")\n",
    "    f.write(\"\\n\\n\\n#####Acabada validacin....\")\n",
    "    f.close()\n",
    "    return bestHyperparameters, X_train, X_val, y_train, y_val, v_early, v_hist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mean and Std of performance metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculateKPI(parameter):\n",
    "    \"\"\"\n",
    "    This function calculate the mean and deviation of a set of values of\n",
    "    a given performance indicator.\n",
    "    \n",
    "    Returns: Mean and std (float)\n",
    "    \"\"\"\n",
    "    mean = round(np.mean(parameter)*100, 2)\n",
    "    deviation = round(np.sqrt(np.sum(np.power(parameter - np.mean(parameter), 2) / len(parameter)))*100, 2)\n",
    "    return mean, deviation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PREDICTIONS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters\n",
    "In the dictionary, hyperparameters related to: data, training, evaluation, regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seeds = [143, 45, 67, 98, 120]\n",
    "input_shape = 80\n",
    "\n",
    "n_time_steps = 14\n",
    "mask_value = 666\n",
    "cost_max = 9\n",
    "cost_start = 4\n",
    "length_infection = 14\n",
    "length_start = 5\n",
    "thresh_AMR_far = 7\n",
    "thresh_after_AMR = 2\n",
    "\n",
    "batch_size = 32\n",
    "n_epochs_max = 10000\n",
    "mindelta = 0\n",
    "patience = 50\n",
    "\n",
    "hyperparameters = {\n",
    "    \"n_time_steps\": n_time_steps,\n",
    "    'mask_value': mask_value,\n",
    "    \"cost_max\": cost_max,\n",
    "    \"cost_start\": cost_start,\n",
    "    \"length_infection\": length_infection,\n",
    "    \"length_start\": length_start,\n",
    "    \"thresh_after_AMR\": thresh_after_AMR,\n",
    "    \"thresh_AMR_far\": thresh_AMR_far,\n",
    "    \n",
    "    'batch_size': batch_size,\n",
    "    'n_epochs_max': n_epochs_max,\n",
    "    'monitor': 'val_loss', \n",
    "    \"mindelta\": mindelta,\n",
    "    \"patience\": patience,\n",
    "    \n",
    "    'kfold':5,\n",
    "    'level':3,\n",
    "    \n",
    "    \"dropout\": 0.0,\n",
    "    \"verbose\": 1\n",
    "}\n",
    "\n",
    "layer_list = [\n",
    "    [input_shape, 3, 1],  [input_shape, 5, 1],  [input_shape, 10, 1], [input_shape, 15, 1], \n",
    "    [input_shape, 20, 1], [input_shape, 25, 1], [input_shape, 40, 1]\n",
    "]\n",
    "\n",
    "dropout = [0.0, 0.15, 0.3]\n",
    "lr_scheduler = [0.01, 0.001, 0.0001]\n",
    "\n",
    "#Output in a structured way\n",
    "tab = \"\\t\" * hyperparameters[\"level\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "v_accuracy_test = []\n",
    "v_specificity = []\n",
    "v_precision = []\n",
    "v_recall = []\n",
    "v_f1score = []\n",
    "v_roc = []\n",
    "v_early = []\n",
    "v_probs = []\n",
    "loss_train = []\n",
    "loss_dev = []\n",
    "results = \"\"\n",
    "v_models = []\n",
    "for i in range(1,6,1):\n",
    "    #Cargo test y pre_train\n",
    "\n",
    "    X_test = np.load(\"../DATA/s\" + str(i) + \"/X_test_tensor_normPower2\" + \".npy\")\n",
    "\n",
    "    y_test = pd.read_csv(\"../DATA/s\" + str(i) + \"/y_test_normPower2\" + \".csv\")\n",
    "    y_test = y_test[['individualMRGerm_stac']]\n",
    "    y_test = y_test.iloc[0:y_test.shape[0]:hyperparameters[\"n_time_steps\"]].reset_index(drop=True)\n",
    "    \n",
    "    #Busco los hiperparmetros y los imprimo    \n",
    "    bestHyperparameters, X_train, X_val, y_train, y_val, v_early, v_hist = myCVGrid(\n",
    "        hyperparameters, dropout, lr_scheduler, layer_list, seeds[i]\n",
    "    )\n",
    "    print(\"\\tlr_sch seleccionado:\", lr_scheduler[bestHyperparameters[\"lr_scheduler\"]])\n",
    "    print(\"\\tdropout seleccionado:\", dropout[bestHyperparameters[\"dropout\"]])\n",
    "    print(\"\\tlayers seleccionado:\", layer_list[bestHyperparameters[\"layers\"]])\n",
    "    f = open(\"0_trazas_GRU.txt\", \"a\")\n",
    "    f.write(\"mejor dropout seleccionado: \"  + str(dropout[bestHyperparameters[\"dropout\"]]) +\n",
    "            \", mejor layers seleccionado: \" + str(layer_list[bestHyperparameters[\"layers\"]]) + \n",
    "            \", mejor lr_sch seleccionado:\" + str(lr_scheduler[bestHyperparameters[\"lr_scheduler\"]]) + \"\\n\")\n",
    "    f.close()\n",
    "    \n",
    "    \n",
    "    hyperparameters = {\n",
    "        'n_time_steps': hyperparameters[\"n_time_steps\"],\n",
    "        'mask_value': hyperparameters[\"mask_value\"],\n",
    "\n",
    "        'cost_max': hyperparameters[\"cost_max\"],\n",
    "        'cost_start': hyperparameters[\"cost_start\"],\n",
    "        'length_infection': hyperparameters[\"length_infection\"],\n",
    "        'length_start': hyperparameters[\"length_start\"],\n",
    "        'thresh_after_AMR': hyperparameters[\"thresh_after_AMR\"],\n",
    "        'thresh_AMR_far': hyperparameters[\"thresh_AMR_far\"],\n",
    "                    \n",
    "        'batch_size': hyperparameters[\"batch_size\"],\n",
    "        'n_epochs_max': hyperparameters[\"n_epochs_max\"],\n",
    "        'monitor':  hyperparameters[\"monitor\"],\n",
    "        \"mindelta\": hyperparameters[\"mindelta\"],\n",
    "        \"patience\": hyperparameters[\"patience\"],\n",
    "                    \n",
    "        \"dropout\": dropout[bestHyperparameters[\"dropout\"]],\n",
    "        \"layers\": layer_list[bestHyperparameters[\"layers\"]],\n",
    "        \"lr_scheduler\": lr_scheduler[bestHyperparameters[\"lr_scheduler\"]],\n",
    "                    \n",
    "        'kfold': hyperparameters[\"kfold\"],\n",
    "        \"level\": 3, \n",
    "        'verbose': 0\n",
    "    }\n",
    "    \n",
    "\n",
    "    #Pruebo en test\n",
    "    reset_keras()\n",
    "    gpu_options = tf.compat.v1.GPUOptions(per_process_gpu_memory_fraction=0.25)\n",
    "    sess = tf.compat.v1.Session(config=tf.compat.v1.ConfigProto(gpu_options=gpu_options))\n",
    "\n",
    "    \n",
    "    model, hist, early = run_network(\n",
    "        X_train, X_val,\n",
    "        y_train, \n",
    "        y_val,\n",
    "        hyperparameters,\n",
    "        seeds[i]\n",
    "    )\n",
    "    \n",
    "    v_models.append(model)\n",
    "    loss_train.append(hist.history['loss'])\n",
    "    loss_dev.append(hist.history['val_loss'])\n",
    "\n",
    "    \n",
    "    y_pred = model.predict(x=X_test)\n",
    "    \n",
    "    accuracy_test = sklearn.metrics.accuracy_score(y_test, np.round(y_pred))\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, np.round(y_pred)).ravel()\n",
    "    roc = sklearn.metrics.roc_auc_score(y_test, y_pred)\n",
    "\n",
    "\n",
    "    v_accuracy_test.append(accuracy_test)\n",
    "    v_specificity.append(tn / (tn + fp))\n",
    "    v_precision.append(tp / (tp + fp))\n",
    "    v_recall.append(tp / (tp + fn))\n",
    "    v_f1score.append((2 * v_recall[i] * v_precision[i]) / (v_recall[i] + v_precision[i]))\n",
    "    v_roc.append(roc)\n",
    "\n",
    "    if debug:\n",
    "        results = results + tab + \"\\tPositivos bien predichos\" + str(tp) + \"\\n\"\n",
    "        results = results + tab + \"\\tPositivos mal predichos\" + str(fp) + \"\\n\"\n",
    "        results = results + tab + \"\\tNegativos bien predichos\" + str(tn) + \"\\n\"\n",
    "        results = results + tab + \"\\tNegativos mal predichos\" + str(fn) + \"\\n\"\n",
    "        \n",
    "        \n",
    "mean_test, deviation_test = calculateKPI(v_accuracy_test)\n",
    "mean_train, deviation_train = calculateKPI(v_accuracy_train)\n",
    "mean_specificity, deviation_specificity = calculateKPI(v_specificity)\n",
    "mean_recall, deviation_recall = calculateKPI(v_recall)\n",
    "mean_f1, deviation_f1 = calculateKPI(v_f1score)\n",
    "mean_precision, deviation_precision = calculateKPI(v_precision)\n",
    "mean_roc, deviation_roc = calculateKPI(v_roc)\n",
    "\n",
    "results = results + tab + \"Accuracy en test:\" + str(mean_test) + \"+-\" + str(deviation_test) + \"\\n\"\n",
    "results = results + tab + \"Accuracy en train: \" + str(mean_train) + \"+-\" + str(deviation_train) + \"\\n\"\n",
    "results = results + tab + \"Especificidad:\" + str(mean_specificity) +  \"+-\" + str(deviation_specificity) + \"\\n\"\n",
    "results = results + tab + \"Sensibilidad:\" + str(mean_recall) +  \"+-\" + str(deviation_recall) + \"\\n\"\n",
    "results = results + tab + \"Precisin:\" + str(mean_precision) +  \"+-\" + str(deviation_precision) + \"\\n\"\n",
    "results = results + tab + \"F1-score:\" + str(mean_f1) + \"+-\" + str(deviation_f1) + \"\\n\"\n",
    "results = results + tab + \"ROC-AUC:\" + str(mean_roc) + \"+-\" + str(deviation_roc) + \"\\n\"\n",
    "\n",
    "results = (results + tab + str(mean_test) + \" +- \" + str(deviation_test) +\n",
    "            ' & ' + str(mean_specificity) +  \" +- \" + str(deviation_specificity) +\n",
    "            ' & ' + str(mean_recall) +  \" +- \" + str(deviation_recall) +\n",
    "            ' & ' + str(mean_f1) + \" +- \" + str(deviation_f1) +\n",
    "            ' & ' + str(mean_roc) + \" +- \" + str(deviation_roc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
