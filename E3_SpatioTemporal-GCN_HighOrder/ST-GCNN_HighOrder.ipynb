{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcd15f6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "import argparse\n",
    "import math\n",
    "import random\n",
    "import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils as utils\n",
    "\n",
    "from script import dataloader, utility, earlystopping\n",
    "from model import models\n",
    "\n",
    "from sklearn.metrics import roc_auc_score, confusion_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecf5840f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset:\n",
    "    def __init__(self):\n",
    "        self.data = {}\n",
    "\n",
    "    def __getattr__(self, name):\n",
    "        if name in self.data:\n",
    "            return self.data[name]\n",
    "        else:\n",
    "            raise AttributeError(f\"'Dataset' object has no attribute '{name}'\")\n",
    "\n",
    "    def __setattr__(self, name, value):\n",
    "        if name == \"data\":\n",
    "            super().__setattr__(name, value)\n",
    "        else:\n",
    "            self.data[name] = value\n",
    "            \n",
    "args = Dataset()\n",
    "\n",
    "args.enable_cuda=True\n",
    "args.seed=42\n",
    "args.dataset='pemsd7-m'\n",
    "args.n_his=14\n",
    "args.n_pred=1\n",
    "args.time_intvl=5\n",
    "args.Kt=3\n",
    "args.stblock_num=2\n",
    "args.act_func='glu'# choices=['glu', 'gtu']\n",
    "args.Ks=3# choices=[3, 2])\n",
    "args.graph_conv_type='high_order_graph_conv' \n",
    "args.gso_type='sym_norm_lap'# choices=['sym_norm_lap', 'rw_norm_lap', 'sym_renorm_adj', 'rw_renorm_adj'])\n",
    "args.enable_bias=True\n",
    "args.droprate=0.5\n",
    "args.lr=0.001\n",
    "args.weight_decay_rate=0.0005\n",
    "args.batch_size=32\n",
    "args.epochs=500\n",
    "args.opt='adam'\n",
    "args.step_size=10\n",
    "args.gamma=0.95\n",
    "args.patience=30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09c01445",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Running in Nvidia GPU (CUDA) or CPU\n",
    "# if args.enable_cuda and torch.cuda.is_available():\n",
    "#     # Set available CUDA devices\n",
    "#     # This option is crucial for multiple GPUs\n",
    "#     # 'cuda' ≡ 'cuda:0'\n",
    "#     device = torch.device('cuda:1')\n",
    "# else:\n",
    "device = torch.device('cpu')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35292647",
   "metadata": {},
   "outputs": [],
   "source": [
    "carpetas = [\"s1\", \"s2\", \"s3\"]\n",
    "\n",
    "numberOfTimeStep=14\n",
    "norm = \"normPower2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47c28c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def exp_kernel(train, sigma):\n",
    "\n",
    "    matrix_train = np.exp(-(train**2)/(2*(sigma**2)))\n",
    "\n",
    "    x = pd.DataFrame(matrix_train)\n",
    "    x = np.round(x, 6)\n",
    "\n",
    "    print(x.loc[0])\n",
    "\n",
    "    return x\n",
    "\n",
    "\n",
    "# Load Ajacency matrix\n",
    "def load_data(carpetas, c, norm, args):\n",
    "    path = \"./dtw_matrices/\"+carpetas[c]+\"/tr_AMR_\"+norm+\".csv\"\n",
    "    dtw_X  = pd.read_csv(path)\n",
    "    adj = exp_kernel(dtw_X, 2.5)\n",
    "    n_vertex = adj.shape[0]\n",
    "\n",
    "    gso = adj.astype(dtype=np.float32)\n",
    "    args.gso = torch.from_numpy(np.array(gso)).to(device)\n",
    "\n",
    "     # Load data\n",
    "    X_train = np.load(\"../DATA/\" + carpetas[c] + \"/X_train_tensor_\"+norm+\".npy\")\n",
    "    y_train = pd.read_csv(\"../DATA/\" + carpetas[c] + \"/y_train_tensor_\"+norm+\".csv\")[['individualMRGerm_stac']].individualMRGerm_stac.values\n",
    "    X_train[X_train == 666] = 0\n",
    "\n",
    "    X_val = np.load(\"../DATA/\" + carpetas[c] + \"/X_val_tensor_\"+norm+\".npy\")\n",
    "    y_val = pd.read_csv(\"../DATA/\" + carpetas[c] + \"/y_val_tensor_\"+norm+\".csv\")[['individualMRGerm_stac']].individualMRGerm_stac.values\n",
    "    X_val[X_val == 666] = 0\n",
    "\n",
    "    X_test = np.load(\"../DATA/\" + carpetas[c] + \"/X_test_tensor_\"+norm+\".npy\")\n",
    "    y_test = pd.read_csv(\"../DATA/\" + carpetas[c] + \"/y_test_tensor_\"+norm+\".csv\")[['individualMRGerm_stac']].individualMRGerm_stac.values\n",
    "    X_test[X_test == 666] = 0\n",
    "\n",
    "\n",
    "    X_train = torch.Tensor(X_train)\n",
    "    X_val = torch.Tensor(X_val)\n",
    "    X_test = torch.Tensor(X_test)\n",
    "\n",
    "    y_train = torch.Tensor(y_train)\n",
    "    y_val = torch.Tensor(y_val)\n",
    "    y_test = torch.Tensor(y_test)\n",
    "\n",
    "    # Paso 1: Redimensionar de PxTxF a PxFxT\n",
    "    X_train = X_train.permute(0, 2, 1)\n",
    "    # Paso 2: Generar una cuarta dimensión replicando los valores de F\n",
    "    x_train = X_train.unsqueeze(-1).expand(-1, -1, -1, X_train.size(1))\n",
    "\n",
    "    X_test = X_test.permute(0, 2, 1)\n",
    "    x_test = X_test.unsqueeze(-1).expand(-1, -1, -1, X_test.size(1))\n",
    "    X_val = X_val.permute(0, 2, 1)\n",
    "    x_val = X_val.unsqueeze(-1).expand(-1, -1, -1, X_val.size(1))\n",
    "\n",
    "\n",
    "    print(\"x_train:\", x_train.shape)\n",
    "    print(\"x_val:\", x_val.shape)\n",
    "    print(\"x_test:\", x_test.shape)\n",
    "\n",
    "    train_data = utils.data.TensorDataset(x_train, y_train)\n",
    "    train_iter = utils.data.DataLoader(dataset=train_data, batch_size=args.batch_size, shuffle=False)\n",
    "    val_data = utils.data.TensorDataset(x_val, y_val)\n",
    "    val_iter = utils.data.DataLoader(dataset=val_data, batch_size=args.batch_size, shuffle=False)\n",
    "    test_data = utils.data.TensorDataset(x_test, y_test)\n",
    "    test_iter = utils.data.DataLoader(dataset=test_data, batch_size=args.batch_size, shuffle=False)\n",
    "    \n",
    "    \n",
    "    return args, train_data, train_iter, val_data, val_iter, test_data, test_iter, n_vertex, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "468ec2ba",
   "metadata": {},
   "source": [
    "# GRIDSEARCH AND PREDICTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d9570c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import roc_auc_score, confusion_matrix\n",
    "import json\n",
    "\n",
    "param_grid = {\n",
    "    \"lr\": [1e-4, 1e-3, 1e-2, 5e-2],  \n",
    "    \"weight_decay_rate\": [0, 1e-5, 1e-4, 1e-3, 1e-2, 1e-1],  \n",
    "    \"droprate\": [0.15,0.3, 0.45],  \n",
    "    \"Ks\": [3, 2], \n",
    "    \"act_func\": ['glu', 'gtu'],\n",
    "    \"graph_conv_type\": [\"high_order_graph_conv\"]\n",
    "}\n",
    "\n",
    "results = []\n",
    "best_params_per_folder = {}\n",
    "\n",
    "for c in range(len(carpetas)):\n",
    "    print(f\"\\n GridSearch for folder {carpetas[c]}/{len(carpetas)}\")\n",
    "\n",
    "    args, train_data, train_iter, val_data, val_iter, test_data, test_iter, n_vertex, y_test = load_data(carpetas, c, norm, args)\n",
    "\n",
    "    best_val_loss = float(\"inf\")\n",
    "    best_params = None\n",
    "    best_model = None\n",
    "\n",
    "    for params in product(*param_grid.values()):\n",
    "        hyperparams = dict(zip(param_grid.keys(), params))\n",
    "        print(f\"Testing configuration: {hyperparams}\")\n",
    "\n",
    "        # Assign hyperparameters to args\n",
    "        args.lr = hyperparams[\"lr\"]\n",
    "        args.weight_decay_rate = hyperparams[\"weight_decay_rate\"]\n",
    "        args.droprate = hyperparams[\"droprate\"]\n",
    "        args.Ks = hyperparams[\"Ks\"]\n",
    "        args.act_func = hyperparams[\"act_func\"]\n",
    "        args.graph_conv_type = hyperparams[\"graph_conv_type\"]\n",
    "\n",
    "        # Define model architecture\n",
    "        Ko = args.n_his - (args.Kt - 1) * 2 * args.stblock_num\n",
    "        blocks = [[n_vertex]] + [[32, 8, 32] for _ in range(args.stblock_num)] + ([[64, 64]] if Ko > 0 else [[64]]) + [[1]]\n",
    "\n",
    "        # Select the type of graph convolution\n",
    "        if args.graph_conv_type == 'high_order_graph_conv':\n",
    "            model = models.STGCNHighOrderGraphConv(args, blocks, n_vertex).to(device)\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported graph_conv_type: {args.graph_conv_type}\")\n",
    "\n",
    "        # Configure optimizer and learning rate scheduler\n",
    "        optimizer = optim.Adam(model.parameters(), lr=args.lr, weight_decay=args.weight_decay_rate)\n",
    "        scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=args.step_size, gamma=args.gamma)\n",
    "        loss_fn = torch.nn.BCELoss()\n",
    "        es = earlystopping.EarlyStopping(mode='min', patience=args.patience)\n",
    "\n",
    "        # Training and validation\n",
    "        for epoch in range(args.epochs):\n",
    "            model.train()\n",
    "            for x, y in train_iter:\n",
    "                y_pred = model(x).squeeze()\n",
    "                loss = loss_fn(y_pred, y)\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "            scheduler.step()\n",
    "\n",
    "            # Validation evaluation\n",
    "            model.eval()\n",
    "            val_loss = sum(loss_fn(model(x).squeeze(), y).item() * y.shape[0] for x, y in val_iter) / sum(y.shape[0] for _, y in val_iter)\n",
    "\n",
    "            if es.step(torch.tensor(val_loss)):\n",
    "                print(\"Early stopping activated.\")\n",
    "                break\n",
    "\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            best_params = hyperparams\n",
    "            best_model = model.state_dict()  # Save the best model state\n",
    "\n",
    "    # Save the best hyperparameters for this folder\n",
    "    best_params_per_folder[f\"folder_{carpetas[c]}\"] = {\n",
    "        \"best_params\": best_params,\n",
    "        \"best_val_loss\": best_val_loss\n",
    "    }\n",
    "    print(f\" Best configuration for folder {c}: {best_params} with validation loss {best_val_loss:.4f}\")\n",
    "\n",
    "    # Load the best model for test evaluation\n",
    "    model.load_state_dict(best_model)\n",
    "    model.eval()\n",
    "\n",
    "    # Evaluate the model on the test set\n",
    "    pred_probs = [model(x_it.unsqueeze(0)).squeeze().item() for x, _ in test_iter for x_it in x]\n",
    "    pred_probs = torch.tensor(pred_probs).cpu().numpy()\n",
    "    y_test = y_test.cpu().numpy()\n",
    "    pred_bin = (pred_probs >= 0.5).astype(int)\n",
    "\n",
    "    # Compute performance metrics\n",
    "    roc_auc = roc_auc_score(y_test, pred_probs)\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, pred_bin).ravel()\n",
    "    sensitivity = tp / (tp + fn)\n",
    "    specificity = tn / (tn + fp)\n",
    "\n",
    "    results.append((roc_auc, sensitivity, specificity))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1444c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "filename = \"model_results.csv\"\n",
    "\n",
    "header = [\"ROC AUC\", \"Sensitivity\", \"Specificity\"]\n",
    "\n",
    "with open(filename, mode=\"w\", newline=\"\") as file:\n",
    "    writer = csv.writer(file)\n",
    "    \n",
    "    writer.writerow(header)\n",
    "    \n",
    "    writer.writerows(results)\n",
    "\n",
    "print(f\"Results saved to {filename}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
